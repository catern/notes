* talk
  TSS integration is based on the principle of,
  you need to be able to run your software

  we couldn't run our software before;
  we could run unit tests,
  and we could maybe run one or a few processes together against a bunch of mocks,
  and we could laboriously configure a bunch of resources to create a "QA system" by copying production
  but we couldn't run the actual system as it was actually intended

  but, once we can run our system,
  well, besides the most obvious use, using it in production,
  the second most obvious use is to run it to test it.

  (er...)

  anyway, so how do we manage to get our system running?
  we have a bunch of processes with complex dependencies,
  and we need to run them.

  this task is actually pretty simple!
  the hard part is understanding how your system actually works,
  but once you've done that;
  this knowledge can be encoded in a regular program.

  [slide(s) about each of the points of the basic type system system stuff]

  OK, that's fairly abstract.
  Let's look at a concrete example now.

  We'll make a test for a specific system.

  I promise you, it doesn't matter what this system does.
  I chose it as an example because it has moderately complicated dependencies,
  but not too complicated.

  The actual complex part, understanding the system,
  has already been done and encoded into the type system by a domain expert.
** building test in the talk
   okay so... the iso validator seems like a good candidate since it depends on marketdata,
   and is reasonably complex yet simple...

   but testing it, is a bit tricky...
   since we need a bump or whatever. hm.

   I suppose bump might not be *that* complex?

   ugh, disseminator... what a complication.

   ok so what's the list

   location, posdelta, disseminator -> hfmd -> feeds, tss_control, venues -> venue sim, static data, fastpath

   tss_control, kinda sucks.

   the rest of these... hmm...

   okay I guess tss_control doesn't suck, it's a real input that WMM uses too...

   posdelta is basically an in-out, a bus to register ourselves on...

   disseminator, sigh, is an annoying indirection, but fine, it's marketdata.

   static_data, ok that's real,

   same with venues and fastpath.
   and location.

   hm.

   I dunno, it's not actually all that complicated I guess

   although if we include the manual trader, then it is complicated, for sure.

   hm. maybe showing bit by bit is kind of irrelevant though.
   I mean, I want to impress with the ease,
   not show the real complexity in this system.

   hmm but if we do include the manual trader it would be so delightfully complete...

   eh... maybe a marketdata example is simpler.
   like, just HFMD

   right, we make staticdata... hmm RegNMSSimulator is a bit complex...

   what about TPS, maybe?

   that one is nice because we can demonstrate that the same code is used to start it in prod!

   hmm and run_tps is pretty simple too.

   yeah this also demonstrates remote usage.

   ok I think TPS is probably the best example.

   we should... porbably clean up some weird stuff that we did.
*** lnc
    hey, how about we just mirror lnc_library in the monorepo?
    treat the HG repo as canonical still, but just mirror it in the monorepo,
    so we can do tests against it?
*** cleaning up TPS
   like, I don't think expecting stuff in CWD is a good idea, anymore...
   I mean... it's just so awkward...
   passing them separately instead of as a bundle is nicer;
   bundling them requires, uh, "consing" a "pair" - making the directory and the symlinks

   a hassle.

   ok so like,
   passing the fds would be even nicer,
   buuuuuuuuuuuuuuuut,
   we don't deal with them as FDs right now so passing them as paths is a smidgen easier

   hm. the ib to tps subaccount mapping.
   it would be nice to pass those... in a more...
   type-y way. hmmm....
   on stdin, maybe...?

   getting rid of "location" entirely would be really nice yeah...

   oh hey. why not just pass it as JSON on the command line?
   as one argument.

   that would be... super easy!

   hmm okay so how do we do persistence if we aren't enforcing a certain layout...
   I guess start_persisting_tps is what enforces it, hmm...

   I guess, there's no real reason to use a symlink now?
   nor ever?
   like, a directory containing some symlinks,
   is no better than a file containing some paths.

   but then again, a file containing some paths is no better than a directory containing some symlinks.

   except, well, that a directory can't be updated atomically... we need the symlink instead.

   and... also I can't use flink stuff sigh
   no linkat with O.TMPFILE

   I guess I can do it with proc, fine.

   although... I do like the...
   fact that the...
   symlinked directories... stay around...

   so it's nice to have all these old rundirs.
*** outline of building test in the talk
    ok so we'll show the method signature of start_tps

    we'll talk about how this is common between prod and test..

    then... run through each argument,
    producing the thing we need...

    hmmm
* prep
(blink-cursor-mode -1)

* TSS Integration talk

** Who is this guy?
Name: Spencer Baugh
Team: Modern Infrastructure for Trading Systems (MITS)
Org: Two Sigma Securities (TSS)

Talk is about:
Testing in TSS with the "TSS Integration" library

1. Brief history of TSS Integration
2. Philosophical discussion of testing (hopefully novel)
3. In-depth example of writing a test with TSS Integration
4. Closing remarks and questions

If something isn't making sense, please ask;
give me the chance to clear it up.

Let's begin!

** Brief history
TSS Integration is:
- a Python library (module name "integration")
- in the monorepo at ts/tss/integration
- discussed in Slack at #x-tss-integration

- Used by teams in TSS and TSI
- Maintained and developed collectively by those teams
- Originally developed by the MITS team in TSS in 2018
- We chose Python so that it could be widely used

To give a sense of scale:
- Fully supports around a hundred different daemons,
  across eight teams.
- Always growing!

But what does it actually do?

** Philosophical discussion

First off:

- TSS Integration is not a "testing library"
- Its purpose is not testing
- It's not even really testing-related

TSS Integration provides
*the ability to run the trading system*

(See http://catern.com/run.html)

I'll explain that a little more.

Two Sigma systems are:
- made up of many different components,
- many different services,
- provided by many different teams.

*The ability to run the trading system*

TSS Integration:
- Runs these components
- Connects these services
- In arbitrary user-controlled configurations 
  (Configurations are not predetermined by the library!)

*The ability to run the trading system*
for any purpose.

| Use case        | Run with TSS Integration?                     |
|-----------------+-----------------------------------------------|
| Development     | Yes                                           |
| Testing         | Yes                                           |
| Profiling       | Yes                                           |
| Production      | For several important subsystems (more soon?) |

*The ability to run the trading system*
anywhere.

There are zero external service dependencies,
so we can run on:
- Core
- Colo
- COIN
- A single homeserver
- The pre-push test farm (we use this heavily)

*The ability to run the trading system*
makes testing much easier.

Here's one explanation:

- Everything makes assumptions about everything else in the system
- If those assumptions are violated, we'll see failures
- So, to test, ideally, just run the system and drive activity through it
- The more you run, the more confident you can be if nothing fails
- (This is why testing in prod is so tempting!)

(See http://catern.com/usertests.html)

So forget about testing for a moment.

Our goal right now:
*The ability to run the trading system*
(in a flexible, robust, portable, self-contained way)

So how do we run the system?

There is no common service framework.

- Many different teams producing many different daemons
- C++, C, Java, Python, etc
- Configuration: Properties, CSVs, YAML, environment variables
- Protocols: Protocolgen, Protobuf, Object Channel, HTTP, etc
- Transports: UDP, TCP, mqueue, iqueue, msgbox, etc
- Etc!

Our solution has to handle all this.

Plus we have all the normal problems!

- service discovery,
- distributed execution,
- process management,
- artifact deployment,
- etc...

And we need to stay portable and avoid external service dependencies.

Again, we need to run in:

- Core
- Colo
- COIN
- A single homeserver
- The pre-push test farm

So Kubernetes, etc, won't work.

So what do we do?

It's not so bad actually.
We can solve this with... a type system.

(See http://catern.com/progsys.html)

A type system!

A basic one, the one your language probably already has

No fancy dependent types, nothing unusual

Quick overview of Python type annotations:
#+begin_src python
var: Foo = make_foo()

def f(arg: Foo) -> ReturnType: ...
#+end_src

About the same as Java or C++;
for more info, see
https://mypy.readthedocs.io/en/stable/cheat_sheet_py3.html

A basic example problem:

Service A connects to services B and C.

Immediate consequences:
- B and C need to start before A
- A needs to know the URLs of B and C

Basically a problem of dependency injection...


[[file:tweet.png]]

*** You can express dependencies between services using function arguments
#+begin_src python
def start_a(b: B, c: C) -> A:
    ...
    start_process([
      "/bin/a",
      "--b-url", b.url,
      "--c-url", c.url,
      ...
    ])
    ...
    return A(...)
#+end_src

The =start_a= function:
- takes values of types =B= and =C=
- returns a value of type =A=
- Internally, starts up service A,
  configuring A using details from the function arguments

Want to start service A?
You need instances of =B= and =C= first,
from =start_b= and =start_c=!

TSS Integration defines such types and functions
for all the services in the trading system.

These objects contain the details required to use the service.

*** You can keep track of complex values using types
Service D can listen on either an HTTP or HTTP2 URL.
Service E can only work with service D if it's in HTTP2 mode.

#+begin_src python
def start_e(d: D[HTTP2Url]) -> E:
    ...
      "--d-url", d.url, # an HTTP2Url
    ...
    return E(...)


def main(d: D[HTTPUrl]) -> E:
    # type error!
    return start_e(d)
#+end_src

The =D= class takes a type argument specifying the type of =d.url=.
(Like Java generics or C++ templates)

*** You can create different environments by passing different arguments
Different use cases need systems configured in different ways.

Service F has an optional dependency on service G;
F changes its behavior depending on whether service G is available.

#+begin_src python
def start_f(g: Optional[G]) -> F:
    ...
    if g:
       ... "--g-url", g.url ...
    else:
       pass
    ...

def environment_one() -> None:
    g = ...
    f = start_f(g)
    ...


def environment_two() -> None:
    f = start_f(None)
    ...
#+end_src

We can use =environment_one= or =environment_two=, each where appropriate.
(See http://catern.com/config.html)

In TSS Integration,
the same functions and types are used for both production and testing.

Different environments are built for production and testing,
out of the same components;
one environment might be for TSS, and the other for TSI.

*** You can interact with a running system using the REPL or debugger
A minor nice feature...

We do this heavily with TSS Integration,
when debugging a system or manipulating it in an ad-hoc way.

#+begin_src python
>> i = start_i(...)
<I object at 0x7fb3a45a4290>
>> j = start_j(i, ...)
<J object at 0x7fb3a45a4490>
>> j.url
"https://example.com"
#+end_src

So that's how TSS Integration approaches running the system.

** In-depth example of writing a test with TSS Integration
We'll look at TPS, the Two sigma Position Service.

What it actually does is not actually relevant, but...

- It's an order gateway
- Receives orders from some mysterious source from the outside
- Validates and possibly rejects those orders
- Updates the TS position daemon, =posdelta=, with any fills

Why TPS?

- The subsystem required to support TPS is relatively small.
- TPS is run by TSS Integration in production.

Our goal:
Put the principles we just discussed into practice

Pretend:
- We're writing the first tests for TPS
  (Normally we'd use the existing =integration/tests/test_tps.py=)
- But we have written TPS types and functions already
- Now let's set up an environment with TPS!

We start with a =TrioTestCase= (an async-enabled =unittest.TestCase=)

We won't show anything async in this example,
so just ignore the =async= and =await= keywords.
#+begin_src python
class TestTPS(TrioTestCase):
    async def asyncSetUp(self) -> None:
        self.tps = await start_tps(...)

    async def test(self) -> None:
        self.assertTrue("Do test stuff")
#+end_src

We'll start up TPS in =asyncSetUp= by calling =start_tps=,
and perform the actual test in =test=.

#+begin_src python
async def start_tps(
  nursery: trio.Nursery,
  thread: Thread,
  listening_sock: FileDescriptor,
  database: integration.tps.Database,
  posdelta: Posdelta,
  publishing_iqueue: PassthroughPublishingIqueue,
  static_data: StaticData,
) -> TPS:
  ...
#+end_src

#+begin_src python
  nursery: trio.Nursery,
#+end_src

- From the open source =trio= library
- Used to start up background asynchronous tasks and detect if they fail
- =self.nursery= (from =TrioTestCase=) is a =trio.Nursery=
  which fails the test if anything in the background fails

#+begin_src python
        self.tps = await start_tps(
            self.nursery,
            ...,
        )
#+end_src

For more info on trio see:
https://trio.readthedocs.io/en/stable/tutorial.html

#+begin_src python
  thread: Thread,
#+end_src

- From the open source =rsyscall= library;
  =rsyscall= lets us start up threads on remote hosts and manipulate them
- This test should just run locally, so we'll use =local_thread=

#+begin_src python
from rsyscall import local_thread

        self.thread = local_thread
        self.tps = await start_tps(
            ...,
            self.thread,
            ...,
        )
#+end_src

For more info on rsyscall see:
https://github.com/catern/rsyscall

#+begin_src python
  listening_sock: FileDescriptor,
#+end_src

- Used by TPS to listen for incoming connections
- Standard Unix socket programming

#+begin_src python
from rsyscall.socket import AF, SOCK
from rsyscall.netinet.in_ import SockaddrIn

        # make a TCP socket
        sock = await self.thread.socket(AF.INET, SOCK.STREAM)
        # bind it to a random port on localhost
        await sock.bind(await self.thread.ptr(SockaddrIn(0, "127.0.0.1")))
        # and start listening
        await sock.listen(1024)
        self.tps = await start_tps(
            ...,
            sock,
            ...,
        )
#+end_src

#+begin_src python
  database: integration.tps.Database,
#+end_src

- Used by TPS as a backend and persistence mechanism
- A SQLite DB will work fine for a test
- =Database.make= will create the DB and initialize it with the TPS schema
- =make_location= returns a directory to store the DB and any other state

#+begin_src python
from integration.lib.utils import make_location
from integration.tps import Database

        self.location = make_location()
        self.tps = await start_tps(
            ...,
            # Use self.thread to make the DB on the right host
            await Database.make(
                self.thread, self.location/"tps.db"),
            ...,
        )
#+end_src

#+begin_src python
  posdelta: Posdelta,
#+end_src

- A service which distributes position updates to clients
- We'll start it with =start_posdelta=

#+begin_src python
async def start_posdelta(
    nursery: trio.Nursery, thread: Thread, workdir: Path,
    ..., # some optional arguments, not relevant here
) -> Posdelta:
#+end_src

- We'll pass the same =trio.Nursery= and =Thread= as we passed to =start_tps=
- =workdir= here is a directory to store state (many daemons need one)
- We can make a subdirectory under the directory from =make_location=

#+begin_src python
        self.tps = await start_tps(
            ...,
            await start_posdelta(
                self.nursery, self.thread, (self.location/"posdelta").mkdir()),
            ...,
        )
#+end_src

#+begin_src python
  publishing_iqueue: PassthroughPublishingIqueue,
#+end_src

- An iqueue (a filesystem-based shared memory communication transport)
- Used by several different services to publish positions to posdelta

#+begin_src python
class PassthroughPublishingIqueue:
    @staticmethod
    async def make(
        thread: Thread,
        path: Path,
        ...,
    ) -> PassthroughPublishingIqueue: ...
#+end_src

- We need a =Thread= and a =Path=,
  to identify the host and path on which to create the iqueue

#+begin_src python
from integration.tps import PassthroughPublishingIqueue

        self.tps = await start_tps(
            ...,
            await PassthroughPublishingIqueue.make(
                self.thread, self.location/"tps.iqx")
            ...,
        )
#+end_src

#+begin_src python
  static_data: StaticData,
#+end_src

- Instrument reference data, stored in files on disk and in-memory
- Used by many services

#+begin_src python
from integration.static_data import StaticData

        self.static_data = await StaticData.make(
            self.thread, (self.location/"static_data").mkdir())
        self.tps = await start_tps(
            ...,
            self.static_data,
        )
#+end_src

That's everything!

#+begin_src python
from integration.static_data import StaticData
from integration.tps import start_tps
from trio import TrioTestCase
from rsyscall import local_thread
from rsyscall.socket import AF, SOCK
from rsyscall.netinet.in_ import SockaddrIn

class TestTPS(TrioTestCase):
    async def asyncSetUp(self) -> None:
        self.thread = local_thread
        sock = await self.thread.socket(AF.INET, SOCK.STREAM)
        await sock.bind(await self.thread.ptr(SockaddrIn(0, "127.0.0.1")))
        await sock.listen(1024)
        self.static_data = await StaticData.make(
            self.thread, (self.location/"static_data").mkdir())
        self.tps = await start_tps(
            self.nursery,
            self.thread,
            sock,
            await Database.make(
                self.thread, self.location/"tps.db"),
            await start_posdelta(
                self.nursery, self.thread, (self.location/"posdelta").mkdir()),
            await PassthroughPublishingIqueue.make(
                self.thread, self.location/"tps.iqx"),
            self.static_data,
        )
#+end_src

Now we start up the Python client for TPS.
The TPS class contains the connection details for TPS,
and helpfully exposes a =make_client= method.

#+begin_src python
    async def asyncSetUp(self) -> None:
        self.tps = ...
        self.client = await self.tps.make_client()
#+end_src

Just send an order and a fill through, for an arbitrary instrument

#+begin_src python
    async def test(self) -> None:
        order = await self.client.new_order(
            'buy', 100, self.static_data.instruments[0], Decimal('50.0'))
        await order.fill(100, Decimal('50.0'))
#+end_src

- This is a complete test (for one kind of event)
- The client (as in production) checks various invariants
- If they're violated, we'll get an exception
- If TPS has an error or crashes, we'll get an exception
- Normally would include other relevant components to enhance the test

* Closing remarks and questions

By making it easy and fast to run the system anywhere,
we've improved our ability to test.

Areas for future development:
- Support for more daemons
- Usage by more teams
- More production usage

More significant long-term development:
- Usage outside Trading Engineering
  (Seigniorage project?)

How to get started?

Add your daemons to TSS Integration, or write your own library

- First, understand the service dependencies of your system
- The rest is just work
- But it's worth it! And then the dependencies are forever codified

Would you like to know more? Or get help starting?
- Shortly, ask me questions
- Later, feel free to join #x-tss-integration and ask
- Look at
  https://gitlab.twosigma.com/main/ts.d/tss.d/integration-git/-/blob/master/README.org

Hopefully this talk has provided some evidence to you
about the importance of being able to run your system.

* planning
** DONE history section
   make smaller?
   maybe move the python details to the example section?

   boopy was impatient about them
** TODO slides
   make text as big as possible

   and have margins
   (setq left-margin-width 10) maybe?
** DONE boopy feedback
   will these slides be available?
   
   margins and big text please!!

   don't say "this example is useless"
   in the example section, lol

   say how to get started/onboarded at the end

   enthusiastically say it's great and very good
   talk about how awesome it is,
   use an emotional appeal
   say it's an investment but it's worth it

   recursive part of the example was maybe too much
   start_posdelta
   maybe skip the optional arguments?
   you're already explaining how to start a service
   it's jarring to start over
   maybe just say, we'd recurse?
   maybe not even show the arguments?
   (I want to show that services vary in complexity to start;
   but boopy says, maybe just show that?)
** TODO remaining boopy feedback
   include lines of code??

   include feature matrix

   a list of features...
   i guesssss that could be handy
   like "doesn't leak processes"
   "easy to clean up after, everything goes in a single directory"
   "runs anywhere, including pre-push, homeservers, or colo"
   "requires no special admin privileges"
   - optimised process startup to avoid the usual monorepo high per-process startup delays
   - distributed execution, can run across multiple hosts
   - arbitrary universes, can run daemons from different universes together
** TODO testing section
   hmm okay, we want to communicate some of those testing ideas...
   maybe they're more appropriate for the philosophy section.

   let's actually put it there?

   yeah because... explaining it during the example is quite tricky.
   we want to prep their minds then show the example.
*** wording
    Taking a running system as a given, we actually benefit from a larger, more complex system.

    From a testing perspective,
    the more code that depends on you and runs successfully,
    the more confident you can be that your implementation is correct.

    This is the same thing that makes "testing in production" so tempting;
    but we don't have to test in production to get it.

    No need to manually write test cases to assert complicated invariants,
    just assert that nothing fails.

    So testing becomes pretty easy with a running system.


    From a testing perspective:

    - Everything makes assumptions about everything else in the system
    - If those assumptions are violated, we'll see failures
    - So testing is easy: Just drive the system with events
*** hmmm
    okay, maybe I should mention including actual assertions in the test?

    although, if I don't mention it...
    it doesn't necessarily say that we *don't* include assertions in other tests.
    just that this one is a complete test.
** TODO end section
*** further elements from README.org
    like the use of REPLs, maybe
*** ending
    Should reaffirm the importance of being able to run your system

    (everywhere, and on the fly?)
* let's actually think
  what should we actually put in the talk?

  so the philosophical section and the example are both good things that I want in the talk...
  so I'll just... treat those as fixed...

  I mean...
  obviously I should be thinking about what effect I want the talk to have.

  ok I feel like the talk is good content-wise right now... maybe?
** DONE post about, running system + contracts is good testing
   Yeah this is what I need.
   I need this post so I can excerpt parts of it and reference it.

   hmm
   also inverse testing?
   does that fit in?

   yeah okay so I guess a blog post about actual testing will be beneficial/necessary

   then we can talk about that at the end of the example (I guess)

   or maybe even in the philosophical discussion part;
   we only waved it off because we didn't actually have anything to say lol.

   ok so then we can just point out how what we're doing complies with that testing approach,
   nice good okay...

   you have error reporting mechanisms in prod,
   like reject messages or error logs or all that
   what if they go wrong? well that's why you have many services
   what if they all go wrong? well why do you expect your test to be any different,
   given that you will certainly not lavish effort on the test that doesn't even run in prod?

   wrote that post!
** TODO post about repl/ide/stuff as UI?
   hm.

   yeah, like... the continuum between a UI,
   and a REPL,
   and how you might want to just,
   compose these objects,
   as an easy way to make a UI..

   hmmm

   also maybe the relationship between like...
   manipulating a UI and programming

   so several things:

   - a repl is a passable UI
   - you can generate a UI from objects and types and declarations
   - manipulating a UI can be a kind of programming;
     macros are one way to breathe fire into this,
     but it seems like there could be other ways
** TODO reformat old posts
   this is completely unrelated but...
   perhaps I should reformat those two old posts I made before ICFP 2017
** TODO rework whole site
   I think I have enough content now that I wouldn't feel weird about doing it...

   we can just keep the old posts around and point at them with links...

   and at the bottom of the main page I can say,
   "for dates and authorship information, clone this site with git"
** ending stuff
   I guess I should just recap the points really.
   run your system,
   and we did it this way.

   and, run your system.

   like,
   "so this all comes from running your system,
   we ran our system using these techniques.

   so, run your system."

   ok so I feel like that's good actually!
   oh but... where should we put discussion of alternative approaches?
   oh, alternative testing approaches I guess can be in the testing section at the end of the example,
   from my future blog post about that.
** ooh good idea
   When doing the example I should put the function signature on a window next to my main window,
   with a split.
   So it stays up there and people can keep track of it.
* 
** their feedback
   not much

the content is interesting
and easy to follow

he said maybe I don't need to have all the detail in the large example,
although he says that he did like the fact that I'm showing everything,
that there's nothing up my sleeve

and it was still easy to follow
** their suggestions
demonstrate the problem at the beginning

talk about why we can't use alternatives
** things I talked about the end
what we had before (mocks, stuff)

product management - people who use it
** their suggestions
give context up front

(my thought: I should probably explain the use of Python typing and Python async up front)
** 
yeah giving context up front makes sense actually, for sure.

obviously I'm jumping right in without context,
and explaining, like...

hey, we want to be able to... test things...
and...
what even is this library we're talking about...

yeah so giving a short history and description of the project management of the library might be useful.
** DONE give details up front
okay so we gave some details about the library and management up front, nice
** TODO give history up front
I'm not sure this is necessary?
** TODO give problem up front
I feel like... this is already covered?
Maybe I should focus more on competing solutions that are unsuitable?

hmm yeah maybe.
the part where I talk about how we need to run pre-push.

maybe between that and saying "a type system",
I can say "and so Kubernetes and COIN etc don't work".

okay yeah! Maybe that's all I need to say.
