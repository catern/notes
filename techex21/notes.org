* talk
  TSS integration is based on the principle of,
  you need to be able to run your software

  we couldn't run our software before;
  we could run unit tests,
  and we could maybe run one or a few processes together against a bunch of mocks,
  and we could laboriously configure a bunch of resources to create a "QA system" by copying production
  but we couldn't run the actual system as it was actually intended

  but, once we can run our system,
  well, besides the most obvious use, using it in production,
  the second most obvious use is to run it to test it.

  (er...)

  anyway, so how do we manage to get our system running?
  we have a bunch of processes with complex dependencies,
  and we need to run them.

  this task is actually pretty simple!
  the hard part is understanding how your system actually works,
  but once you've done that;
  this knowledge can be encoded in a regular program.

  [slide(s) about each of the points of the basic type system system stuff]

  OK, that's fairly abstract.
  Let's look at a concrete example now.

  We'll make a test for a specific system.

  I promise you, it doesn't matter what this system does.
  I chose it as an example because it has moderately complicated dependencies,
  but not too complicated.

  The actual complex part, understanding the system,
  has already been done and encoded into the type system by a domain expert.
** building test in the talk
   okay so... the iso validator seems like a good candidate since it depends on marketdata,
   and is reasonably complex yet simple...

   but testing it, is a bit tricky...
   since we need a bump or whatever. hm.

   I suppose bump might not be *that* complex?

   ugh, disseminator... what a complication.

   ok so what's the list

   location, posdelta, disseminator -> hfmd -> feeds, tss_control, venues -> venue sim, static data, fastpath

   tss_control, kinda sucks.

   the rest of these... hmm...

   okay I guess tss_control doesn't suck, it's a real input that WMM uses too...

   posdelta is basically an in-out, a bus to register ourselves on...

   disseminator, sigh, is an annoying indirection, but fine, it's marketdata.

   static_data, ok that's real,

   same with venues and fastpath.
   and location.

   hm.

   I dunno, it's not actually all that complicated I guess

   although if we include the manual trader, then it is complicated, for sure.

   hm. maybe showing bit by bit is kind of irrelevant though.
   I mean, I want to impress with the ease,
   not show the real complexity in this system.

   hmm but if we do include the manual trader it would be so delightfully complete...

   eh... maybe a marketdata example is simpler.
   like, just HFMD

   right, we make staticdata... hmm RegNMSSimulator is a bit complex...

   what about TPS, maybe?

   that one is nice because we can demonstrate that the same code is used to start it in prod!

   hmm and run_tps is pretty simple too.

   yeah this also demonstrates remote usage.

   ok I think TPS is probably the best example.

   we should... porbably clean up some weird stuff that we did.
*** lnc
    hey, how about we just mirror lnc_library in the monorepo?
    treat the HG repo as canonical still, but just mirror it in the monorepo,
    so we can do tests against it?
*** cleaning up TPS
   like, I don't think expecting stuff in CWD is a good idea, anymore...
   I mean... it's just so awkward...
   passing them separately instead of as a bundle is nicer;
   bundling them requires, uh, "consing" a "pair" - making the directory and the symlinks

   a hassle.

   ok so like,
   passing the fds would be even nicer,
   buuuuuuuuuuuuuuuut,
   we don't deal with them as FDs right now so passing them as paths is a smidgen easier

   hm. the ib to tps subaccount mapping.
   it would be nice to pass those... in a more...
   type-y way. hmmm....
   on stdin, maybe...?

   getting rid of "location" entirely would be really nice yeah...

   oh hey. why not just pass it as JSON on the command line?
   as one argument.

   that would be... super easy!

   hmm okay so how do we do persistence if we aren't enforcing a certain layout...
   I guess start_persisting_tps is what enforces it, hmm...

   I guess, there's no real reason to use a symlink now?
   nor ever?
   like, a directory containing some symlinks,
   is no better than a file containing some paths.

   but then again, a file containing some paths is no better than a directory containing some symlinks.

   except, well, that a directory can't be updated atomically... we need the symlink instead.

   and... also I can't use flink stuff sigh
   no linkat with O.TMPFILE

   I guess I can do it with proc, fine.

   although... I do like the...
   fact that the...
   symlinked directories... stay around...

   so it's nice to have all these old rundirs.
*** outline of building test in the talk
    ok so we'll show the method signature of start_tps

    we'll talk about how this is common between prod and test..

    then... run through each argument,
    producing the thing we need...

    hmmm
* prep
#+begin_src elisp
(progn
  (setq text-scale-mode-amount 5)
  (text-scale-mode 5)
  (blink-cursor-mode -1)
  (setq left-margin-width 0)
  (set-window-buffer
    (get-buffer-window (current-buffer))
    (current-buffer)))
#+end_src

* TSS Integration talk
[[./logo.jpg]]

** Who is this guy?
Spencer Baugh
Modern Infrastructure for Trading Systems (MITS)
Two Sigma Securities (TSS)

Talk is about:
Testing in TSS with the "TSS Integration" library

1. Brief history of TSS Integration
2. Philosophical discussion of testing
3. In-depth example of a test with TSS Integration
4. Closing remarks and questions

If something isn't making sense, please ask!

Let's begin!

** Brief history
TSS Integration is:
- a Python library
- Python module name: "integration"
- monorepo path: ts/tss/integration
- Slack channel: #x-tss-integration
[[./logo.jpg]]

- Used by TSS and TSI
- Maintained collectively by users
- Originally developed by MITS in TSS in 2018
- We chose Python so that it could be widely used

Scale:
- ~100 different services, across ~10 teams.
- ~600 tests
- Used in production for 6 services
- Always growing!

But what does it actually do?

** Philosophical discussion

First off:

- TSS Integration is not a "testing library"
- Its purpose is not testing
- It is not even really testing-related

TSS Integration provides
*the ability to run the trading system*

(See http://catern.com/run.html)

I'll explain that a little more.

Two Sigma systems contain:
- Many different services
- Many different environments
- Many different configurations

*The ability to run the trading system*

TSS Integration:
- Runs these services
- Connects them together
- In arbitrary user-controlled configurations 

Example diagram generated by tss/integration,
of one possible configuration:
[[./diagram.png]]

*The ability to run the trading system*
for any purpose.

| Purpose     | Runs with TSS Integration? |
|-------------+----------------------------|
| Development | Yes                        |
| Testing     | Yes                        |
| Profiling   | Yes                        |
| Production  | Several services           |

*The ability to run the trading system*
anywhere.

There are zero external service dependencies,
so we can run on:
- Core
- Colo
- COIN
- A single homeserver
- The pre-push test farm (we use this heavily)

*The ability to run the trading system*
makes testing much easier.

Here's one explanation:

- Everything makes assumptions about everything else
- If those assumptions are violated, things fail
- So, to test, just run the system
- The more components you run,
  the more confident you can be if nothing fails
- (This is why testing in prod is so tempting!)

(See http://catern.com/usertests.html)

So forget about testing for a moment.

Our goal right now:
*The ability to run the trading system*
in a flexible, robust, portable way.

So how do we run the system?
It's non-trivial.

There's many different kinds of services.

- Languages: C++, C, Java, Python
- Configuration: CSVs, properties, YAML, env vars
- Protocols: Protocolgen, Protobuf, JSON
- Transports: UDP, TCP, mqueue, iqueue, msgbox
- And more!

Our solution has to handle all this.

Plus we have all the normal problems!

- service discovery,
- distributed execution,
- process management,
- artifact deployment,
- etc...

And we need to stay portable,
and avoid external service dependencies.

Again, we run in:

- Core
- Colo
- COIN
- A single homeserver
- The pre-push test farm

So Kubernetes, etc, won't work.

So what do we do?

It's not so bad actually.
We can solve this with... a type system.

(See http://catern.com/progsys.html)

A type system!

A basic one, like C++/Java/Python already have

No fancy dependent types, nothing unusual

Quick overview of Python type annotations:
#+begin_src python
var: Foo = make_foo()

def f(arg: Foo) -> ReturnType: ...
#+end_src

About the same as Java or C++;
for more info, see
https://mypy.readthedocs.io/en/stable/cheat_sheet_py3.html

A basic example problem:

Service A connects to services B and C.

Immediate consequences:
- B and C need to start before A
- A needs to know the URLs of B and C

Basically a problem of dependency injection...


[[file:tweet.png]]

*** Dependencies between services with functions
We can express this with a function!

#+begin_src python
def start_a(b: B, c: C) -> A:
    "Start an instance of the A service"
    ...
    start_process([
      "/bin/a",
      "--b-url", b.url,
      "--c-url", c.url,
      ...
    ])
    ...
    return A(...)
#+end_src

The =start_a= function:
- takes values of types =B= and =C=
- returns a value of type =A=
- Internally, starts up service A,
  configuring A using the function arguments

Want to start service A?
You need instances of =B= and =C= first,
from =start_b= and =start_c=!

TSS Integration, for each service:
- Defines a class A
- Puts all the info to use the service into A
- Defines a function to start the service,
  which returns A,
  and takes dependencies as arguments

*** You can keep track of complex values using types
Service D:
- Speaks either HTTP or HTTP2, but not both
Service E:
- Depends on D
- Requires that D speak HTTP2

#+begin_src python
def start_e(d: D[HTTP2Url]) -> E:
    ...
      "--d-url", d.url, # an HTTP2Url
    ...
    return E(...)


def main(d: D[HTTPUrl]) -> E:
    # type error!
    return start_e(d)
#+end_src

The type argument to the =D= class
specifies the type of =d.url=.
(Like Java generics or C++ templates)

A Two Sigma example:
HFMD tickerplant clients can publish over
- msgbox
- mqueue
- jtmqueue
Types ensure services get the transport they expect

*** Create different envs by passing different args
Service F:
- Can run with or without service G
- Behaves differently if service G is provided
Service G:
- Just some random normal other service

#+begin_src python
def start_f(g: Optional[G]) -> F:
    ...
    if g:
       ... "--g-url", g.url ...
    else:
       pass
    ...

def environment_one() -> None:
    g = ...
    f = start_f(g)
    ...

def environment_two() -> None:
    f = start_f(None)
    ...
#+end_src

We can use =environment_one= or =environment_two=,
each where appropriate.
(See http://catern.com/config.html)

In TSS Integration,
- production/tests/benchmarking
- TSS/TSI
- equities/futures/options
All build different environments,
out of the same components (functions and types).


*** Interact with the system using the REPL/debugger
A minor nice feature...

We do this frequently when debugging a system,
or manipulating it in an ad-hoc way.

#+begin_src python
>> i = start_i(...)
<I object at 0x7fb3a45a4290>
>> j = start_j(i, ...)
<J object at 0x7fb3a45a4490>
>> j.url
"https://example.com"
#+end_src

So that's how TSS Integration provides
*the ability to run the trading system*.


** In-depth example of a test with TSS Integration

TPS, the Two sigma Position Service.

- It's an order gateway (essentially)
- Receives orders from the outside world
- Validates and possibly rejects those orders
- Updates another service, =posdelta=, with fills


Why TPS?

- The subsystem required to support TPS is small.
- TPS is run by TSS Integration in production.

Our goal:
Put the principles we just discussed into practice

Pretend:
- We're writing the first tests for TPS
  (Normally we'd use the existing =test_tps.py=)
- But we've already written TPS types and functions
- Now let's set up an environment with TPS!

We start with a =TrioTestCase=
(an async-enabled =unittest.TestCase=)

We won't show anything async in this example,
so just ignore the =async= and =await= keywords.
#+begin_src python
class TestTPS(TrioTestCase):
    async def asyncSetUp(self) -> None:
        self.tps = await start_tps(...)

    async def test(self) -> None:
        self.assertTrue("Do test stuff")
#+end_src

We'll start up TPS by calling =start_tps=,
and perform the actual test in =test=.

#+begin_src python
async def start_tps(
  nursery: trio.Nursery,
  thread: rsyscall.Thread,
  listening_sock: FileDescriptor,
  database: integration.tps.Database,
  posdelta: Posdelta,
) -> TPS:
  ...
#+end_src

#+begin_src python
  nursery: trio.Nursery,
#+end_src

- Starts and detects failures in background tasks
- self.nursery (from TrioTestCase) is a trio.Nursery
  which fails the test if any background task fails

#+begin_src python
    async def asyncSetUp(self) -> None:
        self.tps = await start_tps(
            self.nursery,
            ...,
        )
#+end_src

For more info on trio see:
https://trio.readthedocs.io/en/stable/tutorial.html

#+begin_src python
  thread: rsyscall.Thread,
#+end_src

- Lets us run things on a remote host
- We'll use =local_thread= to just run locally

#+begin_src python
from rsyscall import local_thread

        self.thread = local_thread
        self.tps = await start_tps(
            ...,
            self.thread,
            ...,
        )
#+end_src

For more info on rsyscall see:
https://github.com/catern/rsyscall

#+begin_src python
  listening_sock: FileDescriptor,
#+end_src

- The first TPS-specific argument
- Used by TPS to listen for incoming connections
- Standard Unix socket programming

#+begin_src python
        # make a TCP socket
        sock = await self.thread.socket(
            AF.INET, SOCK.STREAM)
        # bind it to a random port on localhost
        addr = SockaddrIn(0, "127.0.0.1")
        await sock.bind(await self.thread.ptr(addr))
        # and start listening
        await sock.listen(1024)
        self.tps = await start_tps(
            ...,
            sock,
            ...,
        )
#+end_src

#+begin_src python
  database: integration.tps.Database,
#+end_src

- Used by TPS as a backend and persistence mechanism
- A SQLite DB will work fine for a test
- =Database.make= creates the DB with the TPS schema
- =make_location= returns a temporary directory,
  for databases and any other state

#+begin_src python
        self.location = make_location()
        self.tps = await start_tps(
            ...,
            # Do it on localhost with self.thread
            await Database.make(
                self.thread, self.location/"tps.db"),
            ...,
        )
#+end_src

#+begin_src python
  posdelta: Posdelta,
#+end_src

- Another service; it distributes position updates

#+begin_src python
async def start_posdelta(
    nursery: trio.Nursery, thread: rsyscall.Thread,
    workdir: Path,
    ..., # some optional arguments, irrelevant here
) -> Posdelta:
#+end_src

- Will share =trio.Nursery= and =rsyscall.Thread= with TPS
- =workdir= is a private directory to store state
- Make =workdir= under the dir from =make_location=

#+begin_src python
        self.tps = await start_tps(
            ...,
            await start_posdelta(
                self.nursery, self.thread,
                (self.location/"posdelta").mkdir()),
            ...,
        )
#+end_src

That's everything!

#+begin_src python
class TestTPS(TrioTestCase):
    async def asyncSetUp(self) -> None:
        self.thread = local_thread
        sock = await self.thread.socket(
            AF.INET, SOCK.STREAM)
        addr = SockaddrIn(0, "127.0.0.1")
        await sock.bind(await self.thread.ptr(addr))
        await sock.listen(1024)
        self.tps = await start_tps(
            self.nursery, self.thread,
            sock,
            await Database.make(
                self.thread, self.location/"tps.db"),
            await start_posdelta(
                self.nursery, self.thread,
                (self.location/"posdelta").mkdir()),
        )
#+end_src

Now we start up the Python client for TPS.
The TPS object contains the address for TPS.

#+begin_src python
    async def asyncSetUp(self) -> None:
        self.tps = ...
        self.client = integration.tps.Client(
            await HTTPClient.connect(
                self.thread, self.tps.sockaddr))
#+end_src

Just send an order and fill, for some instrument

#+begin_src python
    async def test(self) -> None:
        order = await self.client.new_order(
            'buy', 100, self.tps.static_data.instruments[0],
            price=Decimal('50.0'))
        await order.fill(100, Decimal('50.0'))
#+end_src

- This is a complete test (for one kind of event)
- The client (as in production) checks invariants
- If they're violated, we'll get an exception
- If TPS errors or crashes, we'll get an exception
- Usually, we'd have more services for more coverage

** Closing remarks and questions

By making it easy to run the system,
we've improved our ability to test.

Summary list of features (for later review):
- type-safe composition and configuration of services without limits
- safe for prod
- runs anywhere, including pre-push, homeservers, or colo
- requires no special privileges
- doesn't depend on any outside services, totally self-contained
- can be used interactively from a REPL or debugger
- optimised process startup to avoid the usual monorepo high per-process startup delays
- distributed execution, can run across multiple hosts
- arbitrary universes, can run services from different universes together
- monitors processes at all times so that any process exits will be detected
- processes can be pinned to CPUs
- doesn't leave stray processes behind
- easy to clean up after, everything goes in a single directory

Areas for future development:
- Support for more services
- Usage by more teams
- More production usage

More significant long-term development:
- Usage outside Trading Engineering
  (Seigniorage project?)

How to get started?

Add your services to TSS Integration,
or write your own library

- First, understand your service dependencies
- The rest is just work
- But it's worth it!
  And then the dependencies are forever codified.

Would you like to know more? Or get help starting?
- Shortly, ask me questions
- Later, feel free to join #x-tss-integration
- Look at ts/tss/integration/README.org
  https://gitlab.twosigma.com/main/ts.d/tss.d/integration-git/-/blob/master/README.org

Hopefully this talk has shown you
the importance of being able to run your system.

Example: trio and rsyscall and remote execution
#+begin_src python
async def start_fooserv(
    nursery: trio.Nursery,
    thread: rsyscall.Thread,
    workdir: Path,
) -> Fooserv:
    command = ts_fooserv.get_c_binary("fooserv").args(
        "--verbose", "--do-stuff-fast",
    )
    child_thread = await thread.clone()
    await child_thread.chdir(workdir)
    child_process = await child.exec(command)
    nursery.start_soon(child_process.check)
    return Fooserv()
#+end_src
* planning
** DONE history section
   make smaller?
   maybe move the python details to the example section?

   boopy was impatient about them
** TODO slides
   make text as big as possible

   and have margins
   (setq left-margin-width 10) maybe?
** DONE boopy feedback
   will these slides be available?
   
   margins and big text please!!

   don't say "this example is useless"
   in the example section, lol

   say how to get started/onboarded at the end

   enthusiastically say it's great and very good
   talk about how awesome it is,
   use an emotional appeal
   say it's an investment but it's worth it

   recursive part of the example was maybe too much
   start_posdelta
   maybe skip the optional arguments?
   you're already explaining how to start a service
   it's jarring to start over
   maybe just say, we'd recurse?
   maybe not even show the arguments?
   (I want to show that services vary in complexity to start;
   but boopy says, maybe just show that?)
** TODO remaining boopy feedback
   include lines of code??

   include feature matrix

   a list of features...
   i guesssss that could be handy
   like
   - type-safe composition and configuration of services without limits
   - safe for prod
   - doesn't leave stray processes behind
   - easy to clean up after, everything goes in a single directory
   - runs anywhere, including pre-push, homeservers, or colo
   - requires no special privileges
   - doesn't depend on any outside services, totally self-contained
   - optimised process startup to avoid the usual monorepo high per-process startup delays
   - distributed execution, can run across multiple hosts
   - arbitrary universes, can run services from different universes together
   - monitors processes at all times so that any process exits will be detected
   - processes can be pinned to CPUs
   - can be used interactively from a REPL or debugger

   lines of code... nah...
** TODO testing section
   hmm okay, we want to communicate some of those testing ideas...
   maybe they're more appropriate for the philosophy section.

   let's actually put it there?

   yeah because... explaining it during the example is quite tricky.
   we want to prep their minds then show the example.
*** wording
    Taking a running system as a given, we actually benefit from a larger, more complex system.

    From a testing perspective,
    the more code that depends on you and runs successfully,
    the more confident you can be that your implementation is correct.

    This is the same thing that makes "testing in production" so tempting;
    but we don't have to test in production to get it.

    No need to manually write test cases to assert complicated invariants,
    just assert that nothing fails.

    So testing becomes pretty easy with a running system.


    From a testing perspective:

    - Everything makes assumptions about everything else in the system
    - If those assumptions are violated, we'll see failures
    - So testing is easy: Just drive the system with events
*** hmmm
    okay, maybe I should mention including actual assertions in the test?

    although, if I don't mention it...
    it doesn't necessarily say that we *don't* include assertions in other tests.
    just that this one is a complete test.
** TODO end section
*** further elements from README.org
    like the use of REPLs, maybe
*** ending
    Should reaffirm the importance of being able to run your system

    (everywhere, and on the fly?)
* let's actually think
  what should we actually put in the talk?

  so the philosophical section and the example are both good things that I want in the talk...
  so I'll just... treat those as fixed...

  I mean...
  obviously I should be thinking about what effect I want the talk to have.

  ok I feel like the talk is good content-wise right now... maybe?
** DONE post about, running system + contracts is good testing
   Yeah this is what I need.
   I need this post so I can excerpt parts of it and reference it.

   hmm
   also inverse testing?
   does that fit in?

   yeah okay so I guess a blog post about actual testing will be beneficial/necessary

   then we can talk about that at the end of the example (I guess)

   or maybe even in the philosophical discussion part;
   we only waved it off because we didn't actually have anything to say lol.

   ok so then we can just point out how what we're doing complies with that testing approach,
   nice good okay...

   you have error reporting mechanisms in prod,
   like reject messages or error logs or all that
   what if they go wrong? well that's why you have many services
   what if they all go wrong? well why do you expect your test to be any different,
   given that you will certainly not lavish effort on the test that doesn't even run in prod?

   wrote that post!
** TODO post about repl/ide/stuff as UI?
   hm.

   yeah, like... the continuum between a UI,
   and a REPL,
   and how you might want to just,
   compose these objects,
   as an easy way to make a UI..

   hmmm

   also maybe the relationship between like...
   manipulating a UI and programming

   so several things:

   - a repl is a passable UI
   - you can generate a UI from objects and types and declarations
   - manipulating a UI can be a kind of programming;
     macros are one way to breathe fire into this,
     but it seems like there could be other ways
** TODO reformat old posts
   this is completely unrelated but...
   perhaps I should reformat those two old posts I made before ICFP 2017
** TODO rework whole site
   I think I have enough content now that I wouldn't feel weird about doing it...

   we can just keep the old posts around and point at them with links...

   and at the bottom of the main page I can say,
   "for dates and authorship information, clone this site with git"
** ending stuff
   I guess I should just recap the points really.
   run your system,
   and we did it this way.

   and, run your system.

   like,
   "so this all comes from running your system,
   we ran our system using these techniques.

   so, run your system."

   ok so I feel like that's good actually!
   oh but... where should we put discussion of alternative approaches?
   oh, alternative testing approaches I guess can be in the testing section at the end of the example,
   from my future blog post about that.
** ooh good idea
   When doing the example I should put the function signature on a window next to my main window,
   with a split.
   So it stays up there and people can keep track of it.
* 
** their feedback
   not much

the content is interesting
and easy to follow

he said maybe I don't need to have all the detail in the large example,
although he says that he did like the fact that I'm showing everything,
that there's nothing up my sleeve

and it was still easy to follow
** their suggestions
demonstrate the problem at the beginning

talk about why we can't use alternatives
** things I talked about the end
what we had before (mocks, stuff)

product management - people who use it
** their suggestions
give context up front

(my thought: I should probably explain the use of Python typing and Python async up front)
** 
yeah giving context up front makes sense actually, for sure.

obviously I'm jumping right in without context,
and explaining, like...

hey, we want to be able to... test things...
and...
what even is this library we're talking about...

yeah so giving a short history and description of the project management of the library might be useful.
** DONE give details up front
okay so we gave some details about the library and management up front, nice
** TODO give history up front
I'm not sure this is necessary?
** TODO give problem up front
I feel like... this is already covered?
Maybe I should focus more on competing solutions that are unsuitable?

hmm yeah maybe.
the part where I talk about how we need to run pre-push.

maybe between that and saying "a type system",
I can say "and so Kubernetes and COIN etc don't work".

okay yeah! Maybe that's all I need to say.
