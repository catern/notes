* talk
  TSS integration is based on the principle of,
  you need to be able to run your software

  we couldn't run our software before;
  we could run unit tests,
  and we could maybe run one or a few processes together against a bunch of mocks,
  and we could laboriously configure a bunch of resources to create a "QA system" by copying production
  but we couldn't run the actual system as it was actually intended

  but, once we can run our system,
  well, besides the most obvious use, using it in production,
  the second most obvious use is to run it to test it.

  (er...)

  anyway, so how do we manage to get our system running?
  we have a bunch of processes with complex dependencies,
  and we need to run them.

  this task is actually pretty simple!
  the hard part is understanding how your system actually works,
  but once you've done that;
  this knowledge can be encoded in a regular program.

  [slide(s) about each of the points of the basic type system system stuff]

  OK, that's fairly abstract.
  Let's look at a concrete example now.

  We'll make a test for a specific system.

  I promise you, it doesn't matter what this system does.
  I chose it as an example because it has moderately complicated dependencies,
  but not too complicated.

  The actual complex part, understanding the system,
  has already been done and encoded into the type system by a domain expert.
** building test in the talk
   okay so... the iso validator seems like a good candidate since it depends on marketdata,
   and is reasonably complex yet simple...

   but testing it, is a bit tricky...
   since we need a bump or whatever. hm.

   I suppose bump might not be *that* complex?

   ugh, disseminator... what a complication.

   ok so what's the list

   location, posdelta, disseminator -> hfmd -> feeds, tss_control, venues -> venue sim, static data, fastpath

   tss_control, kinda sucks.

   the rest of these... hmm...

   okay I guess tss_control doesn't suck, it's a real input that WMM uses too...

   posdelta is basically an in-out, a bus to register ourselves on...

   disseminator, sigh, is an annoying indirection, but fine, it's marketdata.

   static_data, ok that's real,

   same with venues and fastpath.
   and location.

   hm.

   I dunno, it's not actually all that complicated I guess

   although if we include the manual trader, then it is complicated, for sure.

   hm. maybe showing bit by bit is kind of irrelevant though.
   I mean, I want to impress with the ease,
   not show the real complexity in this system.

   hmm but if we do include the manual trader it would be so delightfully complete...

   eh... maybe a marketdata example is simpler.
   like, just HFMD

   right, we make staticdata... hmm RegNMSSimulator is a bit complex...

   what about TPS, maybe?

   that one is nice because we can demonstrate that the same code is used to start it in prod!

   hmm and run_tps is pretty simple too.

   yeah this also demonstrates remote usage.

   ok I think TPS is probably the best example.

   we should... porbably clean up some weird stuff that we did.
*** lnc
    hey, how about we just mirror lnc_library in the monorepo?
    treat the HG repo as canonical still, but just mirror it in the monorepo,
    so we can do tests against it?
*** cleaning up TPS
   like, I don't think expecting stuff in CWD is a good idea, anymore...
   I mean... it's just so awkward...
   passing them separately instead of as a bundle is nicer;
   bundling them requires, uh, "consing" a "pair" - making the directory and the symlinks

   a hassle.

   ok so like,
   passing the fds would be even nicer,
   buuuuuuuuuuuuuuuut,
   we don't deal with them as FDs right now so passing them as paths is a smidgen easier

   hm. the ib to tps subaccount mapping.
   it would be nice to pass those... in a more...
   type-y way. hmmm....
   on stdin, maybe...?

   getting rid of "location" entirely would be really nice yeah...

   oh hey. why not just pass it as JSON on the command line?
   as one argument.

   that would be... super easy!

   hmm okay so how do we do persistence if we aren't enforcing a certain layout...
   I guess start_persisting_tps is what enforces it, hmm...

   I guess, there's no real reason to use a symlink now?
   nor ever?
   like, a directory containing some symlinks,
   is no better than a file containing some paths.

   but then again, a file containing some paths is no better than a directory containing some symlinks.

   except, well, that a directory can't be updated atomically... we need the symlink instead.

   and... also I can't use flink stuff sigh
   no linkat with O.TMPFILE

   I guess I can do it with proc, fine.

   although... I do like the...
   fact that the...
   symlinked directories... stay around...

   so it's nice to have all these old rundirs.
*** outline of building test in the talk
    ok so we'll show the method signature of start_tps

    we'll talk about how this is common between prod and test..

    then... run through each argument,
    producing the thing we need...

    hmmm

* TSS Integration talk

** Who is this guy?
Name: Spencer Baugh
Team: Modern Infrastructure for Trading Systems (MITS)
Hat: Two Sigma Securities (TSS)

Talk is about:
Testing in TSS with the "TSS Integration" library

1. Brief mundane details of TSS Integration
2. Philosophical discussion of testing (hopefully novel)
3. In-depth example of writing a test with TSS Integration
4. Recap of the TSS mindset

If something isn't making sense, please ask;
give me the chance to clear it up.

Let's begin!

** Brief mundane details

- TSS Integration is a Python library
- in the monorepo at ts/tss/integration
- Python module name is "integration"
- Slack channel: #x-tss-integration

- Used by teams in TSS and TSI
- Maintained and developed collectively by those teams
- Originally developed by the MITS team in TSS in 2018
- We chose Python because it's the lowest common denominator

- Fully supports around a hundred different daemons,
  across eight teams.
- Always growing!

- Uses Python type annotations:
#+begin_src python
var: Type = Type()

def f(arg: Type) -> ReturnType: ...
#+end_src

They're rougly as powerful as the Java or C++ type systems;
see https://mypy.readthedocs.io/en/stable/cheat_sheet_py3.html for more info

- Uses async Python:
#+begin_src python
async def f(arg: Type) -> ReturnType:
    x = await g(arg)
    await h(x)
    ...
#+end_src

We use the open source "trio" library for async;
see https://trio.readthedocs.io/en/stable/tutorial.html for more info

It's a normal Python library.

** Philosophical discussion (hopefully novel)

First off:

- TSS Integration is not a "testing library"
- Its purpose is not testing
- It's not even really testing-related

TSS Integration provides this function:

*The ability to run the trading system*

(See http://catern.com/run.html)

*The ability to run the trading system*

Two Sigma systems are:
- made up of many different components,
- many different services,
- provided by many different teams.

*The ability to run the trading system*

TSS Integration:
- Runs these components
- Connects these services
- In arbitrary user-controlled configurations 
- (Configurations are not predetermined by the library!)

*The ability to run the trading system*

| Use case        | Do we actually, for real, do it with TSS Integration today? |
|-----------------+-------------------------------------------------------------|
| Experimentation | Yes                                                         |
| Development     | Yes                                                         |
| Testing         | Yes                                                         |
| Profiling       | Yes                                                         |
| Production      | For several important subsystems (more soon?)               |

*The ability to run the trading system*

There are zero external service dependencies;
so, TSS Integration can run the system anywhere.

- Core
- Colo
- A single homeserver
- The pre-push test farm

*The ability to run the trading system*

- Everything makes assumptions about everything else in the system
- If those assumptions are violated, we'll see failures
- So testing is easy: Just drive the system with external events,
  no need to make up new properties/assertions

(See http://catern.com/usertests.html)

So forget about testing for a moment.

Our goal right now:
*The ability to run the trading system*
(in a flexible, robust, portable, self-contained way)

So how do we run the system?

There is no common service framework.

- Many different teams producing many different daemons
- C++, C, Java, Python, etc
- Configuration: Properties, CSVs, YAML, environment variables
- Protocols: Protocolgen, Protobuf, Object Channel, HTTP, etc
- Transports: UDP, TCP, mqueue, iqueue, msgbox, etc
- Etc!

Our solution has to handle all this.

Plus we have the normal problems!

- service discovery,
- distributed execution,
- process management,
- artifact deployment,
- etc...

And we need to stay portable and avoid external service dependencies.

We need to run in:

- Core
- Colo
- A single homeserver
- The pre-push test farm

So COIN, Kubernetes, etc, won't work.

So what do we do?

It's not so bad actually.
We can solve this with... a type system.

(See http://catern.com/progsys.html)

A type system!

A basic one, the one your language probably already has

No fancy dependent types, nothing unusual

A basic example problem:

Service A connects to services B and C.

Immediate consequences:
- B and C need to start before A
- A needs to know the URLs of B and C

Basically a problem of dependency injection...


[[file:tweet.png]]

** You can express dependencies between services using function arguments.

#+begin_src python
def start_a(b: B, c: C) -> A:
    ...
    start_process([
      "/bin/a",
      "--b-url", b.url,
      "--c-url", c.url,
      ...
    ])
    ...
    return A(...)
#+end_src

=start_a= takes two arguments, of types =B= and =C=,
and returns a value of type =A=.
Internally, it starts up service A,
configuring A using details from the function arguments.

If you want to start service A,
you've got create instances of =B= and =C= first;
presumably by starting services B and C!
That's exactly the invariant we want to enforce.

TSS Integration defines such types and functions,
for all the services and components in the trading system.

These types include all the details required to communicate with the service.

** You can keep track of complex values using types.
Service D can listen on either an HTTP or HTTP2 URL.
Service E can only work with service D if it's in HTTP2 mode.

#+begin_src python
def start_e(d: D[HTTP2Url]) -> E:
    ...
      "--d-url", d.url, # an HTTP2Url
    ...
    return E(...)


def main(d: D[HTTPUrl]) -> E:
    # type error!
    return start_e(d)
#+end_src

The =D= class takes a type argument specifying the type of =d.url=.
(Like Java generics or C++ templates)
** You can create different environments by passing different arguments to functions.
A third and final example.

For different use cases, we'll want systems configured in different ways.

Service F has an optional dependency on service G;
F can run whether or not service G is available.

    #+begin_src python
    def start_f(g: Optional[G]) -> F:
        ...
        if g:
           ... "--g-url", g.url ...
        else:
           pass
        return F(...)

    def environment_one() -> None:
        g = ...
        f = start_f(g)
        ...


    def environment_two() -> None:
        f = start_f(None)
        ...
    #+end_src

We can use =environment_one= or =environment_two=, each where appropriate.
(See http://catern.com/config.html for more general discussion of this specific technique)

In TSS Integration, the same functions and types are used for both production and testing.

Different environments are built out of those components,
using the technique we just saw.

Just one more nice thing with this approach,
you can interact with a running system using the REPL or debugger.

And we do that heavily with TSS Integration,
when debugging a system or manipulating it in an ad-hoc way.

*** In-depth example of writing a test with TSS Integration
We'll look at TPS, the Two sigma Position Service.

What it actually does is not relevant, but...

- It's an order gateway
- Receives orders from the a mysterious source in the outside world
- Validates and possibly rejects those orders
- Updates the TS position daemon, =posdelta=, with the fills (if the order isn't rejected)

Why TPS?

- The subsystem required to support TPS is relatively small.
- TPS is run by TSS Integration in production.

This example is not meant to be practically useful.

Goal:
See how the principles we just discussed are put into practice.

- Pretend we're writing the first tests for TPS
  (Normally we'd use the existing =integration/tests/test_tps.py=)
- We've written TPS types and functions already,
  now let's set up an environment with TPS!

We start with a =TrioTestCase= (an async-enabled =unittest.TestCase=)

#+begin_src python
from integration.tps import start_tps
from integration.lib.trio_test_case import TrioTestCase

class TestTPS(TestCase):
    def setUp(self) -> None:
        self.tps = start_tps(...)

    def test(self) -> None:
        self.assertTrue("Do test stuff")
#+end_src

We'll start up TPS in =setUp= by calling =start_tps=,
and perform the actual test in =test=.

#+begin_src python
async def start_tps(
  nursery: trio.Nursery,
  thread: Thread,
  listening_sock: FileDescriptor,
  database: integration.tps.Database,
  posdelta: Posdelta,
  publishing_iqueue: PassthroughPublishingIqueue,
  static_data: StaticData,
) -> TPS:
  ...
#+end_src


#+begin_src python
  nursery: trio.Nursery,
#+end_src

- From the open source =trio= library
- Used to start up background asynchronous tasks and detect if they fail
- =TrioTestCase= comes with a =trio.Nursery= which fails the test
  if anything in the background fails

#+begin_src python
        self.tps = await start_tps(
            self.nursery,
            ...,
        )
#+end_src

#+begin_src python
  thread: Thread,
#+end_src

- From the open source =rsyscall= library;
  =rsyscall= lets us start up threads on remote hosts and manipulate them
- This test should just run locally, so we'll use =local_thread=

#+begin_src python
from rsyscall import local_thread

        self.thread = local_thread
        self.tps = await start_tps(
            ...,
            self.thread,
            ...,
        )
#+end_src

#+begin_src python
  listening_sock: FileDescriptor,
#+end_src

- Used by TPS to listen for incoming connections
- Standard Unix socket programming

#+begin_src python
from rsyscall.socket import AF, SOCK
from rsyscall.netinet.in_ import SockaddrIn

        # make a TCP socket
        sock = await self.thread.socket(AF.INET, SOCK.STREAM)
        # bind it to a random port on localhost
        await sock.bind(await self.thread.ptr(SockaddrIn(0, "127.0.0.1")))
        # and start listening
        await sock.listen(1024)
        self.tps = await start_tps(
            ...,
            sock,
            ...,
        )
#+end_src

#+begin_src python
  database: integration.tps.Database,
#+end_src

- Used by TPS as a backend and persistence mechanism
- SQLite will work fine for a test
- =Database.make= creates a SQLite DB and initializes the TPS database schema
- We need a path for the database;
  we'll use =make_location= to make a temporary directory
- We use =self.thread= again,
  so the database is created on the same host as everything else

#+begin_src python
from integration.lib.utils import make_location
from integration.tps import Database

        self.location = make_location()
        self.tps = await start_tps(
            ...,
            await Database.make(self.thread, self.location/"tps.db"),
            ...,
        )
#+end_src

#+begin_src python
  posdelta: Posdelta,
#+end_src

- A service which distributes position updates to clients

#+begin_src python
async def start_posdelta(
    nursery: trio.Nursery, workdir: Path,
    static_data: StaticData=None,
    cpu: cpuset.Cpu=None, order_map_size: int=2048,
    filters: t.List[IqsyncFilter]=[],
) -> Posdelta:
#+end_src

- Mostly optional, for customizations we don't care about

#+begin_src python
async def start_posdelta(
    nursery: trio.Nursery, workdir: Path,
    ...,
) -> Posdelta:
#+end_src

- We already have a =trio.Nursery=
- workdir is a directory for the service to store its state;
  we can make it under the directory we made with =make_location= earlier

#+begin_src python
        self.tps = await start_tps(
            ...,
            await start_posdelta(self.nursery, (self.location/"posdelta").mkdir()),
            ...,
        )
#+end_src

#+begin_src python
  publishing_iqueue: PassthroughPublishingIqueue,
#+end_src

- A type of iqueue (a filesystem-based shared memory communication transport)
- Used by several different services (not just TPS) to publish positions to posdelta

#+begin_src python
class PassthroughPublishingIqueue:
    @staticmethod
    async def make(
        thread: Thread,
        path: Path,
        src_id: int=0,
    ) -> PassthroughPublishingIqueue: ...
#+end_src

- We need a =Thread= and a =Path=, to identify the host and path at which to create the iqueue
- The last argument is optional and irrelevant to us for these tests

#+begin_src python
from integration.tps import PassthroughPublishingIqueue

        self.tps = await start_tps(
            ...,
            await PassthroughPublishingIqueue.make(self.thread, self.location/"tps.iqx")
            ...,
        )
#+end_src

#+begin_src python
  static_data: StaticData,
#+end_src

- Instrument reference data, stored in files on disk and in-memory
- Used by many services

#+begin_src python
from integration.static_data import StaticData

        self.static_data = await StaticData.make(self.thread, (self.location/"static_data").mkdir())
        self.tps = await start_tps(
            ...,
            self.static_data,
            ...)
#+end_src


That's everything!

#+begin_src python
from integration.static_data import StaticData
from integration.tps import start_tps
from trio import TrioTestCase
from rsyscall import local_thread
from rsyscall.socket import AF, SOCK
from rsyscall.netinet.in_ import SockaddrIn

class TestTPS(TrioTestCase):
    async def asyncSetUp(self) -> None:
        self.thread = local_thread
        sock = await self.thread.socket(AF.INET, SOCK.STREAM)
        await sock.bind(await self.thread.ptr(SockaddrIn(0, "127.0.0.1")))
        await sock.listen(1024)
        self.static_data = await StaticData.make(self.thread, (self.location/"static_data").mkdir()),
        self.tps = await start_tps(
            self.nursery,
            self.thread,
            sock,
            await Database.make(self.thread, self.location/"tps.db"),
            await start_posdelta(self.nursery, (self.location/"posdelta").mkdir()),
            await PassthroughPublishingIqueue.make(self.thread, self.location/"tps.iqx"),
            self.static_data,
        )
#+end_src


Now we start up the Python client for TPS.
The TPS class contains the connection details for TPS,
and helpfully exposes a =make_client= method.

#+begin_src python
    async def asyncSetUp(self) -> None:
        self.tps = ...
        self.client = await self.tps.make_client()
#+end_src


Just send an order and a fill through, for an arbitrary instrument

#+begin_src python
    async def test(self) -> None:
        order = await self.client.new_order('buy', 100, self.static_data.instruments[0], Decimal('50.0'))
        await order.fill(100, Decimal('50.0')
#+end_src

- This is a complete test (for one kind of event)
- The client (as in production) checks various invariants
- If they're violated, we'll get an exception
- If TPS has an error or crashes, we'll get an exception
- We normally would include other relevant components to test interaction with them too

* Conclusion

By making it easy and fast to run the system,
we've improved our ability to test.

Areas for future development:
- Support for more daemons
- Usage by more teams
- More production usage

More significant, speculative and long-term development:
- Usage outside Trading Engineering

Would you like to know more?
- Now, ask me questions
- Later, feel free to join #x-tss-integration and ask
- Look at https://gitlab.twosigma.com/main/ts.d/tss.d/integration-git/-/blob/master/README.org

Hopefully this talk has provided some evidence to you
about the importance of being able to run your system.
** TODO end section
*** further elements from README.org
    like the use of REPLs, maybe
*** ending
    Should reaffirm the importance of being able to run your system

    (everywhere, and on the fly?)
* planning
** TODO testing section
   hmm okay, we want to communicate some of those testing ideas...
   maybe they're more appropriate for the philosophy section.

   let's actually put it there?

   yeah because... explaining it during the example is quite tricky.
   we want to prep their minds then show the example.
*** wording
    Taking a running system as a given, we actually benefit from a larger, more complex system.

    From a testing perspective,
    the more code that depends on you and runs successfully,
    the more confident you can be that your implementation is correct.

    This is the same thing that makes "testing in production" so tempting;
    but we don't have to test in production to get it.

    No need to manually write test cases to assert complicated invariants,
    just assert that nothing fails.

    So testing becomes pretty easy with a running system.


    From a testing perspective:

    - Everything makes assumptions about everything else in the system
    - If those assumptions are violated, we'll see failures
    - So testing is easy: Just drive the system with events
*** hmmm
    okay, maybe I should mention including actual assertions in the test?

    although, if I don't mention it...
    it doesn't necessarily say that we *don't* include assertions in other tests.
    just that this one is a complete test.
okay fine coool nice
* let's actually think
  what should we actually put in the talk?

  so the philosophical section and the example are both good things that I want in the talk...
  so I'll just... treat those as fixed...

  I mean...
  obviously I should be thinking about what effect I want the talk to have.

  ok I feel like the talk is good content-wise right now... maybe?
** DONE post about, running system + contracts is good testing
   Yeah this is what I need.
   I need this post so I can excerpt parts of it and reference it.

   hmm
   also inverse testing?
   does that fit in?

   yeah okay so I guess a blog post about actual testing will be beneficial/necessary

   then we can talk about that at the end of the example (I guess)

   or maybe even in the philosophical discussion part;
   we only waved it off because we didn't actually have anything to say lol.

   ok so then we can just point out how what we're doing complies with that testing approach,
   nice good okay...

   you have error reporting mechanisms in prod,
   like reject messages or error logs or all that
   what if they go wrong? well that's why you have many services
   what if they all go wrong? well why do you expect your test to be any different,
   given that you will certainly not lavish effort on the test that doesn't even run in prod?

   wrote that post!
** post about repl/ide/stuff as UI?
   hm.

   yeah, like... the continuum between a UI,
   and a REPL,
   and how you might want to just,
   compose these objects,
   as an easy way to make a UI..
** ending stuff
   I guess I should just recap the points really.
   run your system,
   and we did it this way.

   and, run your system.

   like,
   "so this all comes from running your system,
   we ran our system using these techniques.

   so, run your system."

   ok so I feel like that's good actually!
   oh but... where should we put discussion of alternative approaches?
   oh, alternative testing approaches I guess can be in the testing section at the end of the example,
   from my future blog post about that.
** ooh good idea
   When doing the example I should put the function signature on a window next to my main window,
   with a split.
   So it stays up there and people can keep track of it.
* 
** their feedback
   not much

the content is interesting
and easy to follow

he said maybe I don't need to have all the detail in the large example,
although he says that he did like the fact that I'm showing everything,
that there's nothing up my sleeve

and it was still easy to follow
** their suggestions
demonstrate the problem at the beginning

talk about why we can't use alternatives
** things I talked about the end
what we had before (mocks, stuff)

product management - people who use it
** their suggestions
give context up front

(my thought: I should probably explain the use of Python typing and Python async up front)
** 
yeah giving context up front makes sense actually, for sure.

obviously I'm jumping right in without context,
and explaining, like...

hey, we want to be able to... test things...
and...
what even is this library we're talking about...

yeah so giving a short history and description of the project management of the library might be useful.
** DONE give details up front
okay so we gave some details about the library and management up front, nice
** TODO give history up front
I'm not sure this is necessary?
** TODO give problem up front
I feel like... this is already covered?
Maybe I should focus more on competing solutions that are unsuitable?

hmm yeah maybe.
the part where I talk about how we need to run pre-push.

maybe between that and saying "a type system",
I can say "and so Kubernetes and COIN etc don't work".

okay yeah! Maybe that's all I need to say.
