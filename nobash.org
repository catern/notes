#+title: Post about not using bash or config files

Don't use bash or config files.
* no process config
Don't embed a higher level language into your program and write your config in that, either.

Instead, write your config in a nice, type-safe language;
Python with the mypy typechecker works nicely.

Make a nice interface for starting up your application;
you can add lots of types for describing how to configure it.

On the application side, take your configuration as a typed argument in your main function.

The higher-level the better;
prefer, for example, to be passed an already-open socket rather than an IP address and port.

Then - call this function from your "scripting language"!
Create the configuration for your application by building the datatype that your main function takes as an argument.

If your application needs to run in a subprocess,
bridge the gap between the "scripting language" and your application through some serialization framework;
it doesn't matter which one,
it's just a way to provide a cross-language datatype that you can pass to your application's main.

Serialize the config using that framework,
write it to the application (perhaps on stdin or another file descriptor),
and deserialize it in a top-level wrapper for the application
(written in the same language as the application)
which then calls the main function.
* no supervisor config
You don't need to configure a process supervisor, because you don't even need one. 

Don't configure your process supervisor like systemd.
Just supervise your processes yourself.

Then you don't have to "configure" your policies like "how quickly to restart" or "where to put logs".
You can just code those.
Starting processes is the most basic operation in Unix;
you don't need a separate process to handle it.

It can be hard to deal with processes in Unix.
But it can be made much easier with libraries.
You don't need a separate program which opaque, domain-specific configuration to manage it;
you just need a process management library.
* no bash
You don't need to invoke shell commands, because you don't even need one.

Building pipelines of processes is great,
but you can do it in Python just fine,
and you don't have the headaches of writing bash.
(And if you write bash for long enough,
you become braindamaged and start thinking bash is good;
sometimes you can recover though)


Yes, it's harder.
But that's because it's better.
* use argdata
Stop passing files by filename.

Open them, and pass them by file descriptor.

That's slightly harder to use from the shell - but who cares?
We should surpass the shell anyway.

Its many bugs are so engrained in our culture,
that it even tricks people into thinking bugs with the shell,
are actually fundamental bugs in the Unix kernel interface,
instead of just userspace issues. 
* directly calling the c function from python
we could talk about this first,
and then talk about execing.

intredasting.

that is definitely compelling and also makes me not have to explain passing down fds.

yeah that sounds good!

then I can just say:
write a python toplevel instead of a bunch of configuration!

it's much more abstractable and sharable!

much better! and good! and much good!

and if you can't do that, then exec the process instead,
passing down data structures via serialization.

you can avoid passing down filenames and port numbers by opening the files and sockets in advance,
and passing them down over exec.
(You can open files and sockets and other things and then pass them down to a child process in Unix;
it's a little-known ability, because it ranges from extremely painful to impossible to do in bash,
and most people are starting their processes from bash instead of Python!)

Note I say passing down config via serialization.
Don't pass down your config via command line arguments in the traditional Unix style.

Traditional Unix command line arguments (e.g. flags like -t -h -is, mixed with filenames, as well as --these --and=this),
are notoriously vulnerable to confusing "flags" with "values" like filenames;
this is most obvious if you have, say, a file called "-rf" and you call "rm *".

If you use a decent serialization format instead of traditional getopt and its descendents,
this problem goes away.

To prevent the temptation to hand-edit configs,
(instead you should just edit the Python code that generates the config -
ideally extending the high-level code to support your new use case)
prefer to use binary serialization for your config.

This also discourages commiting the configs to source control.

You can pass down your serialized binary config through command line arguments if you remot
* abstract your python, don't just copy your config
Now, the Python code that generates this config should certainly be *abstracted*.
You should not just have a big Python file with a dictionary or something listing all the possible keys and values for configuration.
Those values have *semantic meaning*,
and that meaning should be expressed through *types*.

I have often seen people new to this philosophy just copy their config into Python.
This is not really any better than config files,
because it's exactly the same (or worse) experience to write,
*and* it's unusual and users don't understand why they have to do it.

Instead, you must abstract your config.
Don't just have a bunch of key-values!

If something takes a hostname, or a path, or something;
represent the invariants with a type!

If, when a program A is configured to talk to another B, they must have a bunch of other configs in sync - represent that!
Define the config for program B in one place,
and reuse it when configuring program A to talk to B.
This is easy now that you are using Python for your configuration:
the config for program B is just a function argument for the function which configures program A!
In this way you can easily construct a different program B with different config,
and just call the function for program A with the different config for program B,
and everthing is automatically is sync.

This is the most basic kind of abstraction possible when working in Python;
it's nearly impossible if you're storing your configs in a bunch of JSON or INI or YAML.
* templating
Don't template your config.
That's pointless and stupid.
Your config is a *serialization format* to communicate values from your nice, high-level Python,
to your application which is written in some other language and running in some other process.

If you template your config, you'll be tempted to put values in the templates.
No! You should have everything in Python, where it can be easily abstracted.
Write out your config using the appropriate serializer for JSON or Protobuf or your custom config format.

Templating forces you to be concious of how your data is going to be formatted on disk and your application is going to read it.
That's pointlessly low-level;
you want to remove such worries from your mind permanently,
and for the most part,
stick to manipulating pure Python values which somewhere down the line will be magically communicated to your application.
* DON'T call Python from your application
That is insane and a highway to hell.

What are even the semantics of this?
You start your program with a bit of configuration which points at a Python file,
which it executes and then - pulls the configuration out of some variable?

How does the Python file know what the right type is?

It's inversion of control,
and like all inversion of control,
it's tremendously stupid and pointless and complicates things.

Configuration is a *parameter*.
Pass it as... *a parameter*.

It flows *down* from the top of your program,
you don't randomly magic it out of the filesystem midway through your call stack.
* don't write shell scripts at all
*Why* are you writing a shell script?
Some stupid glue?

Consider that you are a moron and that you shouldn't be doing that.
Just include that glue in your Python code that you have at the top-level.

No shell script *ever* needs to exist.
It is *never* more maintainable to write a shell script than a Python script.
Those who disagree have had their minds sadly poisoned by shell.

They will doubtless raise issues like:
"I can run shell scripts over ssh!"
or
some other stuff.

Eh, let's not try to persuade people to not write bash.

Let's just show them that there is a ton of stuff that they can't do in bash.
And they are severely weakening themselves by not using Python.

Such as serialization,
or directly invoking C main functions,
or passing around file descriptors,
or acessing various system functions.
* why
it's hard to abstract and maintain this configuration,
real languages are better

and they improve!

there has been essentially no improvement in configuration,
because it is a dead end.

there is nowhere to improve.
it's the wrong way to do it.

(or at least, I think it's the wrong way to do it, but that doesn't necessarily mean it couldn't be improved.
but I think it's clear there's been minimal improvement, which I think is suspicious!
since that is what you would see if it *couldn't* be improved!
and if something can't be improved, it's a dead end,
and this is not the dead end where I want to stay forever)

no bash and configuration and json and yaml and stuff!
* create connections ahead of time
??
* no API configuration
Pulumi stuff?

