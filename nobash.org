#+title: Post about not using bash or config files

Don't use bash or config files.
* stop using "configuration files"!
Most programs run in more than one environment;
even if they only ever run in one environment, it's good practice to have at least a little abstraction,
and not hardcode a bunch of ports and paths and preferences.
That stuff that you aren't hardcoding is configuration.

Most people read their configuration out of configuration files;
YAML, JSON, INI, or whatever bespoke formats,
written to disk and read by the daemon.
Sometimes their configuration file is even a programming language,
which they evaluate and load.

Stop doing that!
Your configuration is a bunch of values which you want to pass to your programs.
So just do that instead!
Write a top-level executable file in whatever language, which contains all the configuration values,
and which runs the main function of your program.

Instead of carefully setting things up so your program can find your configuration file,
your configuration top-level executable finds your program, importing it as a library,
through the normal dependency mechanisms for your language.

You can commit that to source control, modify it for different environment, etc, etc, etc.
You can let users write their own top-levels, in whatever language, to configure the program;
you can even give them nice libraries to express the configuration in a high-level way.

That last point - nice libraries to express configuration in a high-level way - is the core of this.
When your configuration is stored in a configuration file,
you can't abstract anything.
Even when it's stored in a file which is evaluated by the program,
written in a programming language with some abstraction capabilities,
you have to manage a bizzare bespoke environment where you run inside another program.
Users don't want to have to deal with that - I certainly don't!

But writing a top-level executable script,
which invokes your program as a library,
is the default case for all programming languages.
It's simple. It's easy. Everyone has dealt with writing top-level executables before.
It's the first thing anyone does in a programming language: Hello, world.

With such a setup, you can easily define reusable modules in your programming language,
which contain configuration shared between many top-levels.
If you are running a program inside a larger environment,
you can write a top-level that references the configs for other top-levels - by just importing them!
You can have types and functions as normal,
and make use of other libraries,
and do whatever you want.

If you want more abstraction, you can easily define more abstraction which wraps your individual application;
your top-level can specify a few tweaks and overrides,
pass them as parameters to a function or modify a class or whatever is natural in your programming language,
and then start your program.

There are some issues with this idealized form,
where you do everything in one language,
a language where the top-levels can be easily modified in-place to reconfigure things.
Let's look at the solutions.
** My program is written in a compiled language.
Is your program written in C or some other compiled language?
Just recompile the top-level every time you want to change configuration.
** My program is written in a compiled language and I don't want to recompile all the time.
OK, that isn't very easy for most developers.
You *should* have a development workflow where it is easy to make a tweak, recompile, retest, and reinstall,
but alas most people do not.

So make bindings for some other higher-level language which you can more easily deploy.
I'll treat Python as a stand-in for "some other higher level language";
pretty much any scripting language would work, so when I say Python, substitute your preferred language.[fn:notpython]
Of course, in modern Python, there's now pretty good static typing support,
so we can using a lot of nice static typing in our configuration, where we can, to ensure it's correct at lint time.

You can even wrap all your C libraries and construct the objects your C application needs *from Python*.

You can delete that huge amount of ugly initialization code that is awkward to write in C.
Just do it from Python instead!
** My program is written in a compiled language, and I don't want to recompile all the time, and I can't embed that language in Python.
There are lots of languages that can't be easily embedded in Python,
but let's just go all the way to the hardest case:
It's quite painful to embed a Java program, hosted on the JVM, into a Python program.

But again the solution is easy,
and indeed this solution is probably what you want to do in *all* cases:
Exec your program written in another language from your Python top-level.

Right before execing your program,
have your Python code serialize out the configuration in some nice encoding on the fly - argdata, say, or protobuf.[fn:getopt][fn:binary]
You can pass file descriptors like socket and open files over exec,
and the new program will be able to use them.[fn:fdpassing]
Argdata supports this nicely.

Pass the serialized configuration down to your program over a pipe,
to avoid your configuration from being morally fouled by coming in conact with the filesystem.
Your configuration is serialized on the fly right before execution,
and is gone after startup,
and the serialization is merely an implementation detail,
rather being the primary form of interaction as with traditional persistent configuration files.

Depending on whatever domain-specific stuff you're doing,
you may be able to pass quite a lot of already-initialized objects across exec.
** I have programs written in multiple languages.
Most non-trivial setups have programs written in multiple langauges.
Luckily, this is also solved by the solution from the previous bullet point:
Just exec the program from your Python top-level.

All your programs in all your languages can be configured in a single, uniform means.
Even if they have totally different and incompatible serialization formats for that configuration!

Indeed, that's the situation I usually find myself in;
every program has its own bespoke native means of serializing down configuration,
but that doesn't matter.
In Python, the interfaces for them are all uniform:
Some arguments, of some types, passed to a function which execs the program.
The unique capabilities of each program are preserved;
but the unnecessary differences in configuring them are removed.
** Further developments
 Now you have all your applications being invoked from Python top-levels,
 and everthing is grand.

 But there's something weird.

 Very often, I want to dynamically generate a value,
 like a port number or a pipe,
 and use it in more than one program.
 But each of my top-levels are independent.
 They can't communicate; so what am I to do?

 Well, unite them!
 Have a new top-level Python script,
 which start multiple programs as subprocesses,
 just by calling the functions you already had in your top-levels.
 Then you can share values between those functions just fine, in Python,
 by passing them as arguments.

 It can be tricky to deal with subprocesses on Unix;
 but there are lots of libraries available to make it easier.

 You might even want to generate a value that needs to be shared across hosts.
 For example, you might want to create an already-connected TCP connection,
 and pass it down to two programs running on different hosts.
 You can do that from Python too, no problem.
 Have your Python top-level start up the subprocesses across multiple hosts;
 again, there are lots of libraries to make this easy.
*** TODO dependencies
 should we mention starting things up in dependency order?
 or monitoring things?

 both of those are achievable with process supervisors.
 they just stink in other ways.

 since you can't control stuff. hmm.
 I guess I shouldn't mention it.

 what are the things I mentioned?
 order dependencies with types;
 that's definitely a cool one sure.

 maybe we *should* mention that.
 you can enforce correct dependencies with types.
 instead of just ad-hoc saying there's a dep.

 that's an advanced notion though, the main thing is simple.
 we would need more examples.
*** TODO monitoring
 you can... make it impossible to start a process and leak it?
 make a process that isn't monitored?

 that's also a relatively advanced notion.
 maybe we should stick to what we have.
* try 2
Many pieces of software use configuration files.
The software is distributed as an executable,
which, when invoked, locates a configuration file in the filesystem and parses it.
This may involving some computation to evaluate the language the configuration file is written in.
Then the software uses the values read from the configuration file to change its behavior.

The user configures the software by writing a configuration file,
locating the file in a place that the software will read,
and running the executable.
Example configuration files may be distributed with the software, which the user may use as a basis.
Advanced or large-scale users
can write programs to generate configuration files,
one per configuration they wish to use.
By sharing code in these programs,
users can share configuration between different configuration files for different environments.

Some examples of software written in this way are Apache HTTPD, GNU Emacs, and bash.

A minority of software takes a different approach.
Instead of being distributed as an executable which reads a configuration file,
the software is distributed as a library.
To use the software, a top-level executable is written in the appropriate programming language,
loading one or more functions from the software's library, and calling them;
typically, these functions will never return.
Configuration is achieved by passing appropriate arguments to those functions.

Some examples of software written in this way are the Xmonad tiling window manager,
(not stumpwm because it's emacs-style)
(insert more examples here - I'm sure there are some, might need to think hard - some things more library-ish?).

The user configures the software by writing a top-level containing their desired configuration,
and running the top-level.
Example top-levels may be distributed with the software, which the user may use as a basis.

Advanced or large-scale users
can have many top-levels,
one per configuration they wish to use.
By sharing code in these top-levels,
users can share configuration between different top-levels for different environments.

# WRONG, this isn't a unique advantage
These top-levels can also have dynamic behavior.
A user can write a single top-level which dynamically (by running user code) discovers the correct configuration for their environment.
The top-level can have some configuration determined statically, and other configuration determined dynamically,
as is appropriate for a user's specific environment.
# EEP EEP EEP! We can also have dynamic behavior with configuration files!
# They can be evaluated and do things wackily!
# ok so that's not too good
# ok so that's not a difference after all.
# we can even open sockets dynamically, hmm, dang.
# well, we can still more easily group together common config with the top-level than with the embedded thing.. right?
# maybe...?
# not necessarily, an easy environment like Emacs, where you have whatever libraries you want,
# allows much sharing easily.
# hm.
# but it's clearly intuitive that having a top-level which invokes multiple,
# is easier to have... *dynamic* sharing, I guess,
# between things.
# right so we can 1. have dynamic things and 2. have shared things which are static,
# but we can't have 3. dynamic things which are shared.
# because we can't invoke multiple from the same language program with config files,
# which we can do when we control the top-level.
# very clear ok yes clear.
# what about the, uhh... hmm. scale thing? point 1?
# well, how would I manage a million emacs instances or something?
# I guess I'd have some init.els which are one way,
# with some aspects dynamically done, and...
# yeah it seems relatively simple and achievable. so scale thing isn't valid either.
# and what about the dependency on config files thing?
# that's kind of an issue of mutable global state isn't it? yeah hmm.
# global state makes it awkward to have multiple instances.
# the top-level makes it easy.
# this is the same thing as with sharing dynamic things between multiple instances in the same top-level?
# hmm. interesting.
# right I can say "the config is here"
# but if it's separate, I don't know what that means
# it's global mutable state, referred to by something else, so changing it would affect elswehere

We can achieve that also with configuration files by synthesizing the two approaches.
# generate config file on the fly and specify it by command line argument

Or, advanced users can write a single top-level which dynamically discovers the correct configuration for their environment.
Or, they can have a hybrid between these two extremes of "static" and "dynamic" configuration.

1. clear upgrade to large scale - small scale and large scale ar identical, programmatic
2. easy move between static and dynamic
3. cleaner dependency story on config files hmmmmm

hmmmmmm so if the application has a configuration file then we can just bind the configuration file wrapped around it.
which hmmmmmmmmm we should highlight as a synthesis
first we highlight that synthesis
then we list all the advantages of the synthesis/dynamic style.


these top-levels may share code through a domain-specific library customized to their specific needs.
Or, they can write a single 
Or, they can have a hybrid between these two extremes of "static" and "dynamic" configuration.

Importantly, when software is configured programmatically in this way,
"static" configuration as supported by configuration files becomes just a special case.
Full dynamic configuration is possible.


can write code to generate configuration files,
one per configuration they wish to use,
using templating or serialization libraries.

Using them as a basis, a user will write their 
and run their top-level to use the software.

Advanced or large-scale users
can have many top-levels,
one per configuration they wish to use,
and can develop their own abstractions on top of the software's interface
to share code using the capabilities of their chosen language.

The top-level locates the program using the language's normal dependency mechanisms.

The user writes code which uses the library;
the user's code is a top-level executable which is executed on its own.

The user's top-level executable locates the program using the language's normal dependency mechanisms,
and passes configuration values as arguments to the program by invoking it as a function.

For the user to configure the program,
they write a top-level that provides their desired configuration values.
Advanced or large-scale users
can have many top-levels, one per environment they want to run within,
and can develop their own abstractions on top of the program's native interface
using the abstraction capabilities of their language.

** abstract type theory pontificating
Fundamentally the difference is whether we have implicit side-effects
(reading configuration files),
or an explicitly typed system,
(passing down configuration through a typed interface).

One could propose a system
where programs were annotated with the configuration files they read,
and even the formats and dependencies of those configuration files.
Then we could create abstractions to simplify and share configuration,
and be statically sure that they are correct.
One might compare this to the development of effect systems in programming language theory,
where functions can be annotated with the side-effects they perform.

But there's a simpler way to achieve an explicitly typed system,
without having to introduce this complicated new annotation functionality in our systems.
Just make the need for configuration (or the need to perform effects) explicit
by making it explicit in the type of the function being invoked:
in the types of the arguments.

* try 3
title: Use static configuration, not dynamic

Most software reads its configuration from somewhere at runtime.

Instead, our first choice should be to hard-code that configuration into the software at build-time.

While it's possible, with enough effort, to statically type the configuration read at runtime,
it's much easier if that composition of "software" and "configuration" happens at build time,
and is static at execution time.
Then we can type-check that composition using normal means.

Multiple configurations can be achieved through multiple executables;
or, at larger scale, reintroduction of dynamism, using inspection of the environment to decide how to be configured.

Most software buries the "configuration" component inside the software.
You start the software, and it looks for configuration in some place,
and reads it and parses it.

Instead, the "configuration" should be the interface for starting the software in the first place.
To run the software, you should provide a configuration,
and in this way allow static types to work.

Ultimately, it's a question of whether we pass configuration as a statically-known function argument,
or as statically-unknown implicit data in the global environment which is read dynamically.
The latter is a popular, traditional approach
but it sacrifices the benefits of static typing.
If we like static typing
so we should pass configuration statically, instead of dynamically.


# don't say dynamic so much though?
# because we can be dynamic.
# we are just doing static composition,
# instead of dynamic composition,
# but we can still dynamically decide configuration values.

In fact, static composition allows for *more* dynamism in configuration compared to the typical alternative.
The composition happens in our normal programming language,
which we can use to dynamically discover details about the environment
and make configuration decisions that are appropriate for our use case.

# of course we don't have to be dynamic if we don't want to, we can be fully static
# maybe shouldn't say "allows for more dynamism", people will want static stuff

where we would have 100 configuration files,
now we have 100 executables.


static composition instead of dynamic composition

Configure software statically, not dynamically


OK, ok, so really I want to say,
"use static composition, not dynamic composition".

That's the Nix philosophy.
Stolen from Nix.

Aha yes late static composition ok ok.

okay

"Static composition is good for configuration"

borrow the Nix thesis terminology.

* try 4
title: Statically link your configuration

Most software "dynamically links" its configuration.
The configuration is written into a configuration file,
which is loaded at runtime from the filesystem.
At runtime, the configuration might not be there,
or it might be the wrong configuration,
or the wrong configuration version,
containing newer or older configuration parameters that don't match the software version.

The same issues are seen when dynamically linking libraries.[fn:dynlibs]
With libraries, we can use static linking (or equivalent techniques[fn:nix]) to avoid these issues.

We can take inspiration from statically linking libraries
and apply equivalent techniques to solve our issues with configuration.
The configuration and the software can be bound together
into an executable that, when run, uses a fixed configuration specified in advance,
rather than looked up at runtime in the filesystem.
This executable can't have the configuration issues we mentioned above;
it shares much of the advantages of static linking in general.

How can we statically link our configuration?
It turns out to be easier and more natural than statically linking libraries.
And it can be done in a way that preserves all the features of a "dynamically linked" configuration,
like having different configurations for different environments.
There are many ways,
but if we're writing a program from scratch,
the easiest is to write that program as a function rather than as an executable.

A typical executable program has a main function which starts up,
reads some configuration files,
and then calls a function to run the real heart of the program,
passing values parsed out of the configuration files.
To statically link the configuration, we just get rid of that hardcoded main function.
Instead, we make our own executable with its own main function,
which directly calls the function that makes up the heart of the program,
passing arguments which describe the desired configuration.
This gives us an executable with statically linked configuration.

Instead of having one configuration file per environment we wish to run in,
we can have one executable per environment we wish to run in.
Instead of separately thinking about deployment of our configuration and deployment of our executable,
we just deploy and run the executable specific to that environment.

Besides the advantages of static linking,
this style also naturally lends itself to statically typed configuration.
Instead of writing a configuration file in JSON, YAML, or some other format,
which can easily have mistakes which will only be caught at configuration load time,
we can write configuration in our normal statically typed language.
For example, instead of using a string to indicate which mode some component should run in,
we can use an enum - and be statically sure that the enum is valid.

This style also makes it easy to abstract over configuration,
and share it between multiple environments.
We can store our shared configurations as data and functions in libraries,
and import and reuse those libraries from each executable
just as we would share any other component.[fn:language_libraries]
We can also have dynamic behavior if we choose to:
We can write code to inspect the environment and verify that it matches expectations,
or decide dynamically what configuration is best based on discovered details.

This doesn't require that we do everything in the same language, either.
If we have, for example, some software in C,
we can call that from an executable written in Python;
we can perform the annoying configuration details in a higher-level language
before passing the completed configuration down to C through a Python binding.
Or, in the most general case, we can have our executable in language A
serialize the configuration in some format[fn:serialization] and pass it directly over stdin
to a stub executable written in language B which we exec.

We can also generalize this notion of "static linking" further, to multi-process, multi-program systems.
In many systems, we start up one process,
and it is "dynamically linked" to other processes by connecting to some port specified in its configuration.
The service listening on that port might not have started,
or might have been replaced by a different incompatible version or different service entirely.
We have no certainty that the port in the configuration is correct.

We can statically link these processes by generalizing the same solution we used for configuration:
Write a program which, instead of starting up one piece of software with some static configuration,
starts up multiple pieces of software, configuring them to talk to each other.
This single parent program can straightforwardly establish a TCP connection or a pipe
and pass each half of that connection down to different components it starts.[fn:fd_passing]
In this way, we can transform a dynamic dependency on the possibly-incorrect open environment,
into a static, guaranteed dependency provided by a single closed program.

I've used all these techniques and found them very effective at reducing complexity.
In the long run,
more information about programs must become statically visible
if we are to create simple and correct large scale systems.
"Statically linking" configuration is one part of that trend.
* abstract your python, don't just copy your config
Now, the Python code that generates this config should certainly be *abstracted*.
You should not just have a big Python file with a dictionary or something listing all the possible keys and values for configuration.
Those values have *semantic meaning*,
and that meaning should be expressed through *types*.

I have often seen people new to this philosophy just copy their config into Python.
This is not really any better than config files,
because it's exactly the same (or worse) experience to write,
*and* it's unusual and users don't understand why they have to do it.

Instead, you must abstract your config.
Don't just have a bunch of key-values!

If something takes a hostname, or a path, or something;
represent the invariants with a type!

If, when a program A is configured to talk to another B, they must have a bunch of other configs in sync - represent that!
Define the config for program B in one place,
and reuse it when configuring program A to talk to B.
This is easy now that you are using Python for your configuration:
the config for program B is just a function argument for the function which configures program A!
In this way you can easily construct a different program B with different config,
and just call the function for program A with the different config for program B,
and everthing is automatically is sync.

This is the most basic kind of abstraction possible when working in Python;
it's nearly impossible if you're storing your configs in a bunch of JSON or INI or YAML.
* no process config
Don't embed a higher level language into your program and write your config in that, either.

Instead, write your config in a nice, type-safe language;
Python with the mypy typechecker works nicely.

Make a nice interface for starting up your application;
you can add lots of types for describing how to configure it.

On the application side, take your configuration as a typed argument in your main function.

The higher-level the better;
prefer, for example, to be passed an already-open socket rather than an IP address and port.

Then - call this function from your "scripting language"!
Create the configuration for your application by building the datatype that your main function takes as an argument.

If your application needs to run in a subprocess,
bridge the gap between the "scripting language" and your application through some serialization framework;
it doesn't matter which one,
it's just a way to provide a cross-language datatype that you can pass to your application's main.

Serialize the config using that framework,
write it to the application (perhaps on stdin or another file descriptor),
and deserialize it in a top-level wrapper for the application
(written in the same language as the application)
which then calls the main function.
** DON'T call Python from your application
 That is insane and a highway to hell.

 What are even the semantics of this?
 You start your program with a bit of configuration which points at a Python file,
 which it executes and then - pulls the configuration out of some variable?

 How does the Python file know what the right type is?

 It's inversion of control,
 and like all inversion of control,
 it's tremendously stupid and pointless and complicates things.

 Configuration is a *parameter*.
 Pass it as... *a parameter*.

 It flows *down* from the top of your program,
 you don't randomly magic it out of the filesystem midway through your call stack.
* templating
Don't template your config.
That's pointless and stupid.
Your config is a *serialization format* to communicate values from your nice, high-level Python,
to your application which is written in some other language and running in some other process.

If you template your config, you'll be tempted to put values in the templates.
No! You should have everything in Python, where it can be easily abstracted.
Write out your config using the appropriate serializer for JSON or Protobuf or your custom config format.

Templating forces you to be concious of how your data is going to be formatted on disk and your application is going to read it.
That's pointlessly low-level;
you want to remove such worries from your mind permanently,
and for the most part,
stick to manipulating pure Python values which somewhere down the line will be magically communicated to your application.
** TODO hmm
I guess I do need to engage with the notion of templating configuration.

Well, as long as someone is doing it on the fly, they are fine.

Well, they might be tempted to write a big Python program
that templates out a bunch of configs and sticks them on disk.

Instead of tying the config and the program together.
Why shouldn't they write out all the configs ahead of time?

well cuz it stinks and, is bad and stuff!
you'll be tempted to commit those files or change them or stuff

hmm. yeah.
let's engage with this

ok one good reason is that you can't do dynamic things.

you can do dynamic things easily and obviously when you're writing your own top-level,
and you can still do dynamic things when you're execing.

but you can't do dynamic things when templating out configs.

it's a bad serialization format.

and by dynamic things I mean stuff like opening a socket or a file and passing it down.
** reframe it
ok so we aren't actually battling templating

we're battling, "write configs in python and then serialize them out to files in advance".
generate config files using abstraction ahead of time.

well, we can't do any runtime stuff;
it makes it hard to just do things.

(although some people would consider that a benefit, because they can generate configs and then parse them, separate steps,
which means they can just run their config generation in a test without running things for real)

but yeah we can't just, y'know.
tie the generation of config for one component to actually running it.

the config generation for a component is very far from the component,
which is wacky.

it's hard to see what's going on!
you have more than one moving part.
you want to reduce the number of moving parts as much as possible.

and part of that is not having config files,
but instead just having your configuration directly in the top-level.

eh I'm just vaguely gesturing here. I need to point at concrete use cases.
but yeah, directly wrapping instead of writing out config before, is the way to go,
and it's what I want to do.

and we shouldn't engage too much with the strawman of just writing config files to disk and committing them.
the strongest form is where you write them out persistently from a program.
because then you can have at least some abstraction.
*** direct style
yeah sure it's direct style,
instead of declarative style.
which is good!

and you can still test it through, say, interpreting the top-levels different by overriding the program exec stuff,
or by um, i had some other idea to write here too.

direct syle not declarative style.
*** approach
ok so I will just make the advantage over properly abstracted written out config files,
explicit,
by comparing against that.

I will also mention abstraction but that's minor.
** clear delineation
clear delineation between config and program:
failures of parsing or construction happen in config toplevel,
not in main program,
so it's clear that it's a config issue.

of course, this requires that the interface to your program is at least somewhat typed,
rather than just receiving a bunch of strings.
the top-level should do the configuration and building of those typed objects,
then pass them down to your program.
** config finds program, program doesn't find config
rather than having the program look for config files,
possibly in some hardcoded place,
possibly overridden by environment variables,
possibly looking in multiple places, falling back to later ones based on priority...

have the config find the program using your normal library discovery methods of your language.
you import the program. no problem.

now you don't have to worry about linking up the config and the program;
it happens automatically using the library discovery tooling your language already has.

whereas previously you would have to worry about putting the config in the right place and all that stuff.
yet more code that you can just delete!
* misc other
** don't write shell scripts at all
 *Why* are you writing a shell script?
 Some stupid glue?

 Consider that you are a moron and that you shouldn't be doing that.
 Just include that glue in your Python code that you have at the top-level.

 No shell script *ever* needs to exist.
 It is *never* more maintainable to write a shell script than a Python script.
 Those who disagree have had their minds sadly poisoned by shell.

 They will doubtless raise issues like:
 "I can run shell scripts over ssh!"
 or
 some other stuff.

 Eh, let's not try to persuade people to not write bash.

 Let's just show them that there is a ton of stuff that they can't do in bash.
 And they are severely weakening themselves by not using Python.

 Such as serialization,
 or directly invoking C main functions,
 or passing around file descriptors,
 or acessing various system functions.
** why no config files?
 it's hard to abstract and maintain this configuration,
 real languages are better

 and they improve!

 there has been essentially no improvement in configuration,
 because it is a dead end.

 there is nowhere to improve.
 it's the wrong way to do it.

 (or at least, I think it's the wrong way to do it, but that doesn't necessarily mean it couldn't be improved.
 but I think it's clear there's been minimal improvement, which I think is suspicious!
 since that is what you would see if it *couldn't* be improved!
 and if something can't be improved, it's a dead end,
 and this is not the dead end where I want to stay forever)

 no bash and configuration and json and yaml and stuff!
** create connections ahead of time
 ??
** no API configuration
 Pulumi stuff?
* research
oh I guess emacs is an example of,
KIND of this.

but it's very different from xmonad style,
where you build the toplevel through explicit passing.

emacs is configuration in the same way - set some global vars,
define some stuff,
just put it around in places and we use it.

it's still inversion of control.

I want to pass my data from the top, down!
not have things look it up in global data!

that is less typed, basically,
if they look it up in a larger datastructure.

passing down the data keeps it nicely typed.
without having to make some crazy effect system.

ok this is a nice insight but it's useless.

except for making it clear that I really hate inversion of control

yeah so emacs is an example of something I don't like;
it reads a config file instead of the user writing the top-level.
** getting rid of inversion of control by expressing path of computation in the type?
hmm, could we fully get rid of inversion of control by like,
having the type say exactly what the computation you need to perform is?

like, um, someone might want to iterate a function 10 times,

which you could enforce the caller doing for you, with the type.

hm.

well or, a function might want to look up some specific string in an environment say,
which you could have the caller do
(and make the looked-up string explicit in the argument type)

yeah that's kind of interesting.

and of course if we don't care about the path of computation then we can just have
the bare type instead of the full path.
* intersection
between,
the config is here.

wait but that's like passing arguments initially?

no because they are mutable if that config isn't constant

if it's constant and specified in the thing that passes it, then no problem

but if it's just some global mutable thing, then it's no different than hardcoding it.

so if it's over there then hmm

ok sure so if it's some global mutable thing then it's no different from hardcoding it, sure.

and also let's compare to say

one toplevel multiple function calls/programs/running things.

easy to manage it.

so what do we gain when we pull the config in?

it's closed over, instead of having some separate mutable thing.

it's a single unit.

also, toplevels are a single unit without reference to external mutable stuff

"We can achieve that also with configuration files by synthesizing the two approaches."

right so we need to show what we gain by the synthesis or by just using toplevels.

it's that, they are closed over units,
without reference to external mutable state,
which is separately managed.

right, when you run it, *you know its configuration*.

so you know what it is going to do.

it's not looking at some other mutable thing which might be set up wrong.

hmm yes.

and more practically this means you can run multiple?

how does that translate to running multiple?

well instead of referencing some mutable external state,
you're just passing in the argument,
which means you can run multiple safely,
because you aren't relying on this other mutable state.

yeah ok. that's cool I like that.

config files are this mutable state,
which we have a reference too.

but if we pass them immutably by value,
then we don't have to worry about the state changing,
and we can run multiple instances because they don't have a shared mutable state.

hmm. something like that.

how does that translate to shared dynamic things?

not sure. hm.

so if we have a single config and we invoke all of them using that single config,
they can dynamically decide things hmmmm

dunno.

hmmm.

ok.
so.
if we have immutable configs passed down, instead of read out of a shared mutable place,
that is good. obv.

those can include functions or dynamically generated values or all that stuff.

what about this sharing of dynamic things?

so if I have a config which is read out of a shared mutable place.

then.

well that shared mutable place is also *serialized* which is the real issue isn't it?

so 1. it's serialized to text and 2. put in a shared mutable place.

are those the two issues?

so we could have it 1. serialized to text but not 2. put in a shared mutable place;
and that would be fine and cool.

er wait.

even if it was serialized to text, we could have like port numbers,
which are picked dynamically but can't be shared even though they are serialized to text.

hmm.

so we do some dynamic thing.

and... it needs some communication means between the config files.
and that's a huge hassle to do across multiple processes/interpreters,
but very easy from a single interpreter.

so. that's kind of also that it's serialized to text then.

if I just asked some mutable shared object "hey give me some stuff",
it could do it just fine.

so yeah if there was some system daemon,
where talking to it went over serialization,
but it was shared and mutable um.

wait okay so it's not really that it's a shared mutable place then or that it's sreialized is it.

because yeah actually these config files could contact a system daemon or something to achieve sharing of dynthings.

even though they are serialized to text.

but obviously that's a hassle, hm.

so okay, that is a still more advanced form of "configuration files":
contact a daemon to get your config.

why don't we like that?

it's clearly still inversion of control, but why don't we like it?

so - of course we need to not be prejudicial! maybe we do like it!

so I contact a daemon to get my config,
and then I can have dynamically created things shared.

I can even have file descriptors passed back to me,
fine fine.

it's hacky, and more complicated, but it can work.

so why does this suck?
well, it's substantially more complicated - but why?

well let's compare it to if the system daemon was the parent, hm.

that could be the same anyway - the parent could pass down the pipe or something,
and the child read off the config.

hmm.

so all this seems quite complex though! it's really just very complex!

so we invert control by having each started up thing receive its config from some central daemon.
which is a hack, because then there's this central thing.

which we might *also* want to change, so.

we never escape this central mutable shared thing.

we always ultimately have a want for the parent to pass something down?

right because the path to the daemon would be passed by the parent;
or more likely, hardcoded, possibly in some shell script wrapper.

and it isn't dynamic, but everything else can be.

but then we have this same issue...
if I want to start something up with different config,
i.e. config not provided by that daemon,
I have to pass something down anyway.

and if I'm passing something down, why not pass everything down?

hmm.

but at least this is a big advance - a system daemon providing config!
we should have considered that long before.

really that's kind of like a big mutable shared object in a language;
where you have some global DI framework thing and you load config from it.

why does that suck?
** hmm
but lots of languages like having dynscope for configuration.

HM.

well, they are dumb and bad.
they should be typed!

but yeah that's just a lack of typing, hmm.

so is this just, "statically type your configuration"?

yeah I mean the issue with not knowing what config file you have,
not knowing if it's initialized:

that's the same thing with invoking a function that depends on a dynvar instead of a closure.

i don't know what will happen, it uses the dynvar, it's totally wacky!

and closure, I provide the config, it's much better!

at least this provides a good language for these concerns

and a much simpler footing to talk about it

because I can just talk about types rather than all this other stuff about files and whatever

I steelman'd the alternative as much as I could and it came down to dynamic scope vs static types.

dynamic scope is untyped, deeply, I guess;
implicit parameters are a different thing, which are much better

ok so I can still have the right types in the file and test that at build time I guess
this thing does that I guess https://github.com/cbeust/konfig

but I don't know... what values are used?

so what does this correspond to?
it corresponds to, having the config in one large statically typed dynscoped thing.

well but we don't know *what* config a specific executable will use.

even if I guess we have checks that the binding will be compatible.

well, yeah, we know the file will be valid,
but we don't know 1. it will be in the right place,
2. the right file will be there,
or 3. what file will be used (that is kind of 1 and 2 also really)

yeah, it comes down to using dynscope, or using a closure.

not really static types.
although static types are a bonus.


Use static configuration, not dynamic

is kinda the idea

well how's that relative to the header thing that dwm has?
** nix
static composition for configuration

yeah yeah yeah

it's better, and also a good foundation for other things?
like types and dynamism? hmm.

well it doesn't enable anything except for correctness.

yeah I mean it's clearly more correctness.
more static assertion that things are right

I want to just link to this page of the Nix thesis.

https://nixos.org/~eelco/pubs/phd-thesis.pdf#page=178



Well it's late binding vs early binding.

although the thesis claims it is orthogonal to late vs early binding. hm.


ok so I could say:

"Statically link your configuration"

as the title.

I think the thesis's claim that they're orthogonal is confused.

I'll just say, statically link.

yeah heh this is totally different focus from what I had initially

so we finally realized that it's static composition that I wanted

the rest of it can be achieved through dynamic composition,
just, kinda horribly.

hmm I could talk about how this naturally extends to dynamic sharing.

but then again you could do that with a configuration daemon

but that stinks anyway, this is statically composed instead of depending on the daemon!
no need to depend on that daemon running!

hm
* Footnotes

[fn:language_libraries]
To be clear, we're talking about using language-level libraries.
For example, in Python one could have a library with shared configuration
which is imported with "import" from several different executable toplevels
which all share the configuration from that library,
with tweaks for their specific needs.
No different from a normal library.

[fn:nix]
Some package managers, such as Nix, technically use dynamically linked libraries,
but the packaging is set up in such a way that the dynamically linked libraries are constant and immutable,
meaning the deployment experience is much like static linking.
This is in some sense "morally" static linking,
even though it is technically dynamic linking.
This is mostly irrelevant to us here, in any case.

[fn:dynlibs]
# TODO talk about the issues of dynamic linking in more depth?
Dynamic linking libraries has substantial advantages too, of course.
But they mostly don't apply in the case of configuration.

The most important advantage is the efficiency benefits,
which don't apply in the case of configuration.
The ability to upgrade every program using a library at once
also doesn't really apply for most configuration scenarios.

I think [[https://nixos.org/~eelco/pubs/phd-thesis.pdf#page=178][section 7.1.1 of the Nix thesis]] has a nice, concise summary of some issues
about static and dynamic linking.

[fn:serialization] 
Protobuf and argdata are some nice binary[fn:binary] serialization formats.

[fn:fd_passing]
In Unix, any file descriptor (which includes sockets) can be passed down to a child process
and used by that child process.
So, a parent process can create some sockets, and then pass them down to its children.

[fn:binary]
To prevent the temptation to hand-edit configs,
(instead you should just edit the Python code that generates the config -
ideally extending the high-level code to support your new use case)
prefer to use binary serialization for your config.

This also discourages commiting the configs to source control.

You can pass down your serialized binary config through command line arguments,
if you find some serialization format which eliminates null bytes.
That would allow you to nicely avoid an unnecessary pipe;
unfortunately Unix pointlessly requires arguments to not have null bytes,
but it has no other restrictions.


[fn:getopt]
Note I say passing down config via serialization.
Don't pass down your config via command line arguments in the traditional Unix style.

Traditional Unix command line arguments (e.g. flags like -t -h -is, mixed with filenames, as well as --these --and=this),
are notoriously vulnerable to confusing "flags" with "values" like filenames;
this is most obvious if you have, say, a file called "-rf" and you call "rm *".

If you use a decent serialization format instead of traditional getopt and its descendents,
this problem goes away.

[fn:fdpassing] 
Most people don't pass file descriptors down because it doesn't work well with possibly-incompatible configuration files.
But you don't have that problem anymore!
It also is incredibly painful to do from bash.

[fn:notpython]
Certainly Python isn't my favorite high level language either.
But, alas, many people are familiar with it, and this is a fairly radical article,
and I don't want to propose something even more radical and out there,
like using a language with types.

